{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -rf ./wide_mixnet_poly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%config IPCompleter.greedy=True\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run ./datagen.py\n",
    "datagen, (x_train, y_train), (x_test, y_test) = data_preparation()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_dir = './wide_mixnet_poly/'\n",
    "batch_size = 100\n",
    "iterations = x_train.shape[0] // batch_size\n",
    "epochs = 500\n",
    "old_acc = 0\n",
    "start_lr = 1e-3\n",
    "end_lr = 1e-4\n",
    "decay_rate = (end_lr / start_lr) ** (1 / epochs)\n",
    "k = 4\n",
    "# regularizer = tf.contrib.layers.l2_regularizer(scale=1e-5)\n",
    "initializer=tf.initializers.he_normal()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# resnet layer\n",
    "def res_layer(inputs, filter_num, filter_size, stride, is_train,\n",
    "              batch_norm=True, activation=True):\n",
    "\n",
    "    x = inputs\n",
    "\n",
    "    if batch_norm:\n",
    "        x = tf.layers.batch_normalization(x, training=is_train)\n",
    "    if activation:\n",
    "        x = tf.nn.relu(x)\n",
    "    x = tf.layers.conv2d(inputs=x, filters=filter_num, \n",
    "                         kernel_initializer=initializer, \n",
    "                         kernel_size=filter_size, strides=stride, padding='same')\n",
    "        \n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def wide_resnet(inputs, k, is_train):\n",
    "\n",
    "    with tf.variable_scope(\"1st_Conv\"):\n",
    "        x = tf.layers.conv2d(inputs=inputs, filters=16, \n",
    "                             kernel_initializer=initializer, \n",
    "                             kernel_size=3, strides=1, padding='same')\n",
    "        x = tf.layers.batch_normalization(x, training=is_train)\n",
    "        x = tf.nn.relu(x)\n",
    "\n",
    "    # Res Blocks\n",
    "    a = [1, 1, 1]\n",
    "    block_num = 0\n",
    "\n",
    "    for stack in range(len(a)):\n",
    "        for block in range(a[stack]):\n",
    "\n",
    "            with tf.variable_scope('ResBlock_%d_%d' % (stack+1, block+1)):\n",
    "\n",
    "                batch_norm = True\n",
    "                activation = True\n",
    "                stride = 1\n",
    "                filter_num = 16*k*(2**stack)\n",
    "                if stack == 0:\n",
    "                    if block == 0:\n",
    "                        batch_norm = False\n",
    "                        activation = False\n",
    "                else:  \n",
    "                    if block == 0:\n",
    "                        stride = 2\n",
    "\n",
    "                shortcut = x\n",
    "                with tf.variable_scope('conv1'):\n",
    "                    x = res_layer(x, filter_num, 3, stride, is_train, \n",
    "                                  batch_norm=batch_norm, activation=activation)\n",
    "                    \n",
    "                x = tf.layers.dropout(x, 0.1)\n",
    "                \n",
    "                with tf.variable_scope('conv2'):\n",
    "                    x = res_layer(x, filter_num, 3, 1, is_train)\n",
    "                \n",
    "                with tf.variable_scope('x_plus_shortcut'):\n",
    "                    if block == 0:\n",
    "                        shortcut = tf.layers.conv2d(inputs=shortcut, filters=filter_num, \n",
    "                                                    kernel_size=1, strides=stride, padding='same')\n",
    "                    x = x + shortcut\n",
    "    \n",
    "    with tf.variable_scope(\"AfterResBlock\"):\n",
    "        x = tf.layers.batch_normalization(x, training=is_train)\n",
    "        x = tf.nn.relu(x)\n",
    "        x = tf.layers.average_pooling2d(x, pool_size=8, strides=8, padding='SAME', name='ave_pool')\n",
    "    \n",
    "    with tf.variable_scope(\"Flatten\"):\n",
    "        x = tf.transpose(x, perm=[0, 3, 1, 2])\n",
    "        x = tf.layers.flatten(x)\n",
    "    \n",
    "    # crrent x.shape = (?, 256)\n",
    "    with tf.variable_scope(\"Prediction\"):\n",
    "        pred = tf.layers.dense(x, units=10, kernel_initializer=initializer)\n",
    "        \n",
    "    return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def wide_mixnet(inputs, k, is_train):\n",
    "\n",
    "    with tf.variable_scope(\"1st_Conv\"):\n",
    "        x = tf.layers.conv2d(inputs=inputs, filters=16, \n",
    "                             kernel_initializer=initializer, \n",
    "                             kernel_size=3, strides=1, padding='same')\n",
    "        x = tf.layers.batch_normalization(x, training=is_train)\n",
    "        x = tf.nn.relu(x)\n",
    "    \n",
    "    x_temp_0 = x\n",
    "    \n",
    "    with tf.variable_scope('ResBlock_%d_%d' % (1, 1)):\n",
    "        \n",
    "        with tf.variable_scope('conv1'):\n",
    "            x = res_layer(x, 16*k, 3, 1, is_train, \n",
    "                          batch_norm=False, activation=False)\n",
    "                    \n",
    "        x = tf.layers.dropout(x, 0.1)\n",
    "                \n",
    "        with tf.variable_scope('conv2'):\n",
    "            x = res_layer(x, 16*k, 3, 1, is_train)\n",
    "    \n",
    "        with tf.variable_scope('x_plus_shortcut'):\n",
    "            shortcut = tf.layers.conv2d(inputs=x_temp_0, filters=16*k, \n",
    "                                        kernel_size=1, strides=1, padding='same')\n",
    "            x = x + shortcut             \n",
    "        \n",
    "    x_temp_1 = x\n",
    "    \n",
    "    with tf.variable_scope('ResBlock_%d_%d' % (2, 1)):\n",
    "        \n",
    "        with tf.variable_scope('conv1'):\n",
    "            x = res_layer(x, 32*k, 3, 2, is_train)\n",
    "                    \n",
    "        x = tf.layers.dropout(x, 0.1)\n",
    "                \n",
    "        with tf.variable_scope('conv2'):\n",
    "            x = res_layer(x, 32*k, 3, 1, is_train)\n",
    "            \n",
    "        with tf.variable_scope('x_plus_shortcut'):\n",
    "            shortcut = tf.layers.conv2d(inputs=x_temp_0, filters=32*k, \n",
    "                                        kernel_size=1, strides=2, padding='same')\n",
    "            x = x + shortcut\n",
    "            \n",
    "            shortcut = tf.layers.conv2d(inputs=x_temp_1, filters=32*k, \n",
    "                                        kernel_size=1, strides=2, padding='same')\n",
    "            x = x + shortcut\n",
    "        \n",
    "    x_temp_2 = x    \n",
    "    \n",
    "    with tf.variable_scope('ResBlock_%d_%d' % (3, 1)):\n",
    "        \n",
    "        with tf.variable_scope('conv1'):\n",
    "            x = res_layer(x, 64*k, 3, 2, is_train)\n",
    "                    \n",
    "        x = tf.layers.dropout(x, 0.1)\n",
    "                \n",
    "        with tf.variable_scope('conv2'):\n",
    "            x = res_layer(x, 64*k, 3, 1, is_train)\n",
    "            \n",
    "        with tf.variable_scope('x_plus_shortcut'):\n",
    "            \n",
    "            shortcut = tf.layers.conv2d(inputs=x_temp_0, filters=64*k, \n",
    "                                        kernel_size=1, strides=4, padding='same')\n",
    "            x = x + shortcut\n",
    "\n",
    "            shortcut = tf.layers.conv2d(inputs=x_temp_1, filters=64*k, \n",
    "                                        kernel_size=1, strides=4, padding='same')\n",
    "            x = x + shortcut\n",
    "\n",
    "            shortcut = tf.layers.conv2d(inputs=x_temp_2, filters=64*k, \n",
    "                                        kernel_size=1, strides=2, padding='same')\n",
    "            x = x + shortcut\n",
    "\n",
    "    with tf.variable_scope(\"AfterResBlock\"):\n",
    "        x = tf.layers.batch_normalization(x, training=is_train)\n",
    "        x = tf.square(x)\n",
    "        x = tf.layers.average_pooling2d(x, pool_size=8, strides=8, padding='SAME', name='ave_pool')\n",
    "\n",
    "    with tf.variable_scope(\"Flatten\"):\n",
    "        x = tf.transpose(x, perm=[0, 3, 1, 2])\n",
    "        x = tf.layers.flatten(x)\n",
    "\n",
    "    with tf.variable_scope(\"Prediction\"):\n",
    "        pred = tf.layers.dense(x, units=10, kernel_initializer=initializer)\n",
    "        \n",
    "    return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From <ipython-input-7-38d4aaa9a591>:6: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.conv2d instead.\n",
      "WARNING:tensorflow:From <ipython-input-7-38d4aaa9a591>:7: batch_normalization (from tensorflow.python.layers.normalization) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.batch_normalization instead.\n",
      "WARNING:tensorflow:From <ipython-input-7-38d4aaa9a591>:18: dropout (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.dropout instead.\n",
      "WARNING:tensorflow:From <ipython-input-7-38d4aaa9a591>:78: average_pooling2d (from tensorflow.python.layers.pooling) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.average_pooling2d instead.\n",
      "WARNING:tensorflow:From <ipython-input-7-38d4aaa9a591>:82: flatten (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.flatten instead.\n",
      "WARNING:tensorflow:From <ipython-input-7-38d4aaa9a591>:85: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.dense instead.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/losses/losses_impl.py:209: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"5\"\n",
    "\n",
    "tf.reset_default_graph()\n",
    "\n",
    "with tf.device('/GPU:5'):\n",
    "\n",
    "    inputs = tf.placeholder(tf.float32, [None, 32, 32, 3], name='input')\n",
    "    outputs = tf.placeholder(tf.float32, [None, 10], name='output')\n",
    "    is_train = tf.placeholder(tf.bool, name='is_train')\n",
    "\n",
    "    global_step = tf.Variable(0, trainable=False)\n",
    "\n",
    "    l_r = tf.train.exponential_decay(\n",
    "        start_lr, global_step, iterations, decay_rate, staircase=True)\n",
    "    tf.summary.scalar('learning_rate', l_r)\n",
    "\n",
    "    opt = tf.train.AdamOptimizer(learning_rate=l_r)\n",
    "\n",
    "    pred = wide_mixnet(inputs, k, is_train)\n",
    "    \n",
    "#     l2_loss = tf.losses.get_regularization_loss()\n",
    "    loss = tf.losses.softmax_cross_entropy(outputs, pred)\n",
    "    \n",
    "    grads = opt.compute_gradients(loss)\n",
    "\n",
    "    correct_pred = tf.equal(tf.argmax(pred, 1), tf.argmax(outputs, 1))\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))\n",
    "\n",
    "#     for grad, var in grads:\n",
    "#         if grad is not None:\n",
    "#             tf.summary.histogram(var.name.split(\":\")[0] + '/gradients', grad)\n",
    "\n",
    "    update_ops = tf.get_collection(tf.GraphKeys.UPDATE_OPS)\n",
    "\n",
    "    with tf.control_dependencies(update_ops):\n",
    "        train_op = opt.apply_gradients(grads, global_step=global_step)\n",
    "\n",
    "#     kernel_vars = []\n",
    "\n",
    "#     for i in tf.trainable_variables():\n",
    "#         if 'bin/kernel' in i.name:\n",
    "#             kernel_vars.append(i)\n",
    "\n",
    "#     with tf.control_dependencies(update_ops):\n",
    "#         with tf.control_dependencies([train_op]):\n",
    "#             kernel_clip_op = [tf.clip_by_value(var, -1, 1) for var in kernel_vars]\n",
    "\n",
    "    saver = tf.train.Saver(tf.global_variables(), max_to_keep=4)\n",
    "\n",
    "#     def add_hist(train_vars):\n",
    "#         for i in train_vars:\n",
    "#             name = i.name.split(\":\")[0] + '/value'\n",
    "#             value = i.value()\n",
    "#             tf.summary.histogram(name, value)\n",
    "\n",
    "#     add_hist(tf.trainable_variables())\n",
    "\n",
    "    tf.summary.scalar('loss', loss)\n",
    "    tf.summary.scalar('accuracy', accuracy)\n",
    "    merged = tf.summary.merge_all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*****************Training Start!*****************\n",
      "Epoch: 1 Train_loss: 1.115 Val_acc: 0.545 Time consumed: 45.8281 s\n",
      "Epoch: 2 Train_loss: 0.806 Val_acc: 0.729 Time consumed: 42.1131 s\n",
      "Epoch: 3 Train_loss: 0.678 Val_acc: 0.750 Time consumed: 42.3344 s\n",
      "Epoch: 4 Train_loss: 0.647 Val_acc: 0.765 Time consumed: 42.1676 s\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/python/training/saver.py:966: remove_checkpoint (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use standard file APIs to delete files with this prefix.\n",
      "Epoch: 5 Train_loss: 0.523 Val_acc: 0.779 Time consumed: 42.3106 s\n",
      "Epoch: 6 Train_loss: 0.426 Val_acc: 0.813 Time consumed: 42.2679 s\n",
      "Epoch: 7 Train_loss: 0.606 Val_acc: 0.827 Time consumed: 42.0302 s\n",
      "Epoch: 8 Train_loss: 0.600 Val_acc: 0.806 Time consumed: 41.9538 s\n",
      "Epoch: 9 Train_loss: 0.324 Val_acc: 0.813 Time consumed: 42.2209 s\n",
      "Epoch: 10 Train_loss: 0.245 Val_acc: 0.844 Time consumed: 42.3847 s\n",
      "Epoch: 11 Train_loss: 0.338 Val_acc: 0.826 Time consumed: 42.1867 s\n",
      "Epoch: 12 Train_loss: 0.367 Val_acc: 0.837 Time consumed: 41.9341 s\n",
      "Epoch: 13 Train_loss: 0.275 Val_acc: 0.852 Time consumed: 42.3913 s\n",
      "Epoch: 14 Train_loss: 0.296 Val_acc: 0.857 Time consumed: 42.3011 s\n",
      "Epoch: 15 Train_loss: 0.358 Val_acc: 0.850 Time consumed: 42.2192 s\n",
      "Epoch: 16 Train_loss: 0.372 Val_acc: 0.846 Time consumed: 42.0361 s\n",
      "Epoch: 17 Train_loss: 0.239 Val_acc: 0.831 Time consumed: 42.3436 s\n",
      "Epoch: 18 Train_loss: 0.271 Val_acc: 0.851 Time consumed: 42.2787 s\n",
      "Epoch: 19 Train_loss: 0.176 Val_acc: 0.842 Time consumed: 42.4091 s\n",
      "Epoch: 20 Train_loss: 0.262 Val_acc: 0.836 Time consumed: 42.3395 s\n",
      "Epoch: 21 Train_loss: 0.346 Val_acc: 0.828 Time consumed: 42.1921 s\n",
      "Epoch: 22 Train_loss: 0.216 Val_acc: 0.862 Time consumed: 42.8927 s\n",
      "Epoch: 23 Train_loss: 0.293 Val_acc: 0.834 Time consumed: 42.1333 s\n",
      "Epoch: 24 Train_loss: 0.188 Val_acc: 0.870 Time consumed: 42.3664 s\n",
      "Epoch: 25 Train_loss: 0.191 Val_acc: 0.881 Time consumed: 42.4552 s\n",
      "Epoch: 26 Train_loss: 0.150 Val_acc: 0.849 Time consumed: 42.2686 s\n",
      "Epoch: 27 Train_loss: 0.154 Val_acc: 0.866 Time consumed: 41.9787 s\n",
      "Epoch: 28 Train_loss: 0.106 Val_acc: 0.863 Time consumed: 42.1017 s\n",
      "Epoch: 29 Train_loss: 0.134 Val_acc: 0.827 Time consumed: 42.2303 s\n",
      "Epoch: 30 Train_loss: 0.119 Val_acc: 0.874 Time consumed: 42.1187 s\n",
      "Epoch: 31 Train_loss: 0.187 Val_acc: 0.867 Time consumed: 42.3390 s\n",
      "Epoch: 32 Train_loss: 0.227 Val_acc: 0.868 Time consumed: 42.2470 s\n",
      "Epoch: 33 Train_loss: 0.145 Val_acc: 0.884 Time consumed: 42.6600 s\n",
      "Epoch: 34 Train_loss: 0.150 Val_acc: 0.875 Time consumed: 42.2593 s\n",
      "Epoch: 35 Train_loss: 0.172 Val_acc: 0.860 Time consumed: 42.2562 s\n",
      "Epoch: 36 Train_loss: 0.139 Val_acc: 0.863 Time consumed: 42.0748 s\n",
      "Epoch: 37 Train_loss: 0.192 Val_acc: 0.864 Time consumed: 42.1744 s\n",
      "Epoch: 38 Train_loss: 0.171 Val_acc: 0.863 Time consumed: 42.4885 s\n",
      "Epoch: 39 Train_loss: 0.120 Val_acc: 0.878 Time consumed: 42.6276 s\n",
      "Epoch: 40 Train_loss: 0.057 Val_acc: 0.892 Time consumed: 42.9588 s\n",
      "Epoch: 41 Train_loss: 0.131 Val_acc: 0.889 Time consumed: 42.1214 s\n",
      "Epoch: 42 Train_loss: 0.087 Val_acc: 0.888 Time consumed: 42.2238 s\n",
      "Epoch: 43 Train_loss: 0.116 Val_acc: 0.879 Time consumed: 42.1912 s\n",
      "Epoch: 44 Train_loss: 0.055 Val_acc: 0.879 Time consumed: 42.0480 s\n",
      "Epoch: 45 Train_loss: 0.143 Val_acc: 0.881 Time consumed: 42.2969 s\n",
      "Epoch: 46 Train_loss: 0.077 Val_acc: 0.880 Time consumed: 42.2483 s\n",
      "Epoch: 47 Train_loss: 0.145 Val_acc: 0.891 Time consumed: 42.3781 s\n",
      "Epoch: 48 Train_loss: 0.167 Val_acc: 0.889 Time consumed: 42.4357 s\n",
      "Epoch: 49 Train_loss: 0.115 Val_acc: 0.889 Time consumed: 42.4829 s\n",
      "Epoch: 50 Train_loss: 0.053 Val_acc: 0.884 Time consumed: 42.5732 s\n",
      "Epoch: 51 Train_loss: 0.078 Val_acc: 0.894 Time consumed: 42.9197 s\n",
      "Epoch: 52 Train_loss: 0.097 Val_acc: 0.883 Time consumed: 42.2407 s\n",
      "Epoch: 53 Train_loss: 0.118 Val_acc: 0.885 Time consumed: 42.2551 s\n",
      "Epoch: 54 Train_loss: 0.161 Val_acc: 0.877 Time consumed: 42.2906 s\n",
      "Epoch: 55 Train_loss: 0.104 Val_acc: 0.891 Time consumed: 42.2722 s\n",
      "Epoch: 56 Train_loss: 0.085 Val_acc: 0.879 Time consumed: 42.2623 s\n",
      "Epoch: 57 Train_loss: 0.053 Val_acc: 0.889 Time consumed: 42.4148 s\n",
      "Epoch: 58 Train_loss: 0.174 Val_acc: 0.892 Time consumed: 42.4488 s\n",
      "Epoch: 59 Train_loss: 0.103 Val_acc: 0.884 Time consumed: 42.5506 s\n",
      "Epoch: 60 Train_loss: 0.111 Val_acc: 0.876 Time consumed: 42.6415 s\n",
      "Epoch: 61 Train_loss: 0.053 Val_acc: 0.894 Time consumed: 43.1552 s\n",
      "Epoch: 62 Train_loss: 0.040 Val_acc: 0.885 Time consumed: 42.1720 s\n",
      "Epoch: 63 Train_loss: 0.048 Val_acc: 0.889 Time consumed: 42.4158 s\n",
      "Epoch: 64 Train_loss: 0.073 Val_acc: 0.872 Time consumed: 42.2141 s\n",
      "Epoch: 65 Train_loss: 0.165 Val_acc: 0.893 Time consumed: 42.4488 s\n",
      "Epoch: 66 Train_loss: 0.023 Val_acc: 0.898 Time consumed: 42.9174 s\n",
      "Epoch: 67 Train_loss: 0.011 Val_acc: 0.884 Time consumed: 42.2440 s\n",
      "Epoch: 68 Train_loss: 0.059 Val_acc: 0.895 Time consumed: 42.1869 s\n",
      "Epoch: 69 Train_loss: 0.045 Val_acc: 0.905 Time consumed: 42.5022 s\n",
      "Epoch: 70 Train_loss: 0.055 Val_acc: 0.897 Time consumed: 42.1584 s\n",
      "Epoch: 71 Train_loss: 0.071 Val_acc: 0.880 Time consumed: 42.2640 s\n",
      "Epoch: 72 Train_loss: 0.037 Val_acc: 0.884 Time consumed: 42.2990 s\n",
      "Epoch: 73 Train_loss: 0.044 Val_acc: 0.890 Time consumed: 42.3259 s\n",
      "Epoch: 74 Train_loss: 0.020 Val_acc: 0.889 Time consumed: 42.2957 s\n",
      "Epoch: 75 Train_loss: 0.035 Val_acc: 0.890 Time consumed: 42.5049 s\n",
      "Epoch: 76 Train_loss: 0.085 Val_acc: 0.888 Time consumed: 42.8033 s\n",
      "Epoch: 77 Train_loss: 0.057 Val_acc: 0.891 Time consumed: 42.3256 s\n",
      "Epoch: 78 Train_loss: 0.048 Val_acc: 0.884 Time consumed: 42.7000 s\n",
      "Epoch: 79 Train_loss: 0.071 Val_acc: 0.888 Time consumed: 42.5854 s\n",
      "Epoch: 80 Train_loss: 0.037 Val_acc: 0.875 Time consumed: 42.7776 s\n",
      "Epoch: 81 Train_loss: 0.030 Val_acc: 0.894 Time consumed: 42.7253 s\n",
      "Epoch: 82 Train_loss: 0.102 Val_acc: 0.889 Time consumed: 42.5307 s\n",
      "Epoch: 83 Train_loss: 0.045 Val_acc: 0.897 Time consumed: 42.7230 s\n",
      "Epoch: 84 Train_loss: 0.014 Val_acc: 0.894 Time consumed: 42.8024 s\n",
      "Epoch: 85 Train_loss: 0.017 Val_acc: 0.880 Time consumed: 42.7833 s\n",
      "Epoch: 86 Train_loss: 0.031 Val_acc: 0.889 Time consumed: 42.7914 s\n",
      "Epoch: 87 Train_loss: 0.044 Val_acc: 0.886 Time consumed: 42.5857 s\n",
      "Epoch: 88 Train_loss: 0.027 Val_acc: 0.891 Time consumed: 42.5189 s\n",
      "Epoch: 89 Train_loss: 0.026 Val_acc: 0.887 Time consumed: 42.7915 s\n",
      "Epoch: 90 Train_loss: 0.059 Val_acc: 0.897 Time consumed: 42.5810 s\n",
      "Epoch: 91 Train_loss: 0.012 Val_acc: 0.892 Time consumed: 42.5837 s\n",
      "Epoch: 92 Train_loss: 0.016 Val_acc: 0.892 Time consumed: 42.7475 s\n",
      "Epoch: 93 Train_loss: 0.113 Val_acc: 0.894 Time consumed: 42.9055 s\n",
      "Epoch: 94 Train_loss: 0.035 Val_acc: 0.897 Time consumed: 42.6650 s\n",
      "Epoch: 95 Train_loss: 0.067 Val_acc: 0.896 Time consumed: 42.8754 s\n",
      "Epoch: 96 Train_loss: 0.038 Val_acc: 0.888 Time consumed: 42.6486 s\n",
      "Epoch: 97 Train_loss: 0.024 Val_acc: 0.898 Time consumed: 42.7485 s\n",
      "Epoch: 98 Train_loss: 0.152 Val_acc: 0.898 Time consumed: 42.8283 s\n",
      "Epoch: 99 Train_loss: 0.034 Val_acc: 0.897 Time consumed: 42.7384 s\n",
      "Epoch: 100 Train_loss: 0.046 Val_acc: 0.882 Time consumed: 42.8117 s\n",
      "Epoch: 101 Train_loss: 0.012 Val_acc: 0.899 Time consumed: 42.7714 s\n",
      "Epoch: 102 Train_loss: 0.010 Val_acc: 0.891 Time consumed: 43.2367 s\n",
      "Epoch: 103 Train_loss: 0.147 Val_acc: 0.891 Time consumed: 42.2330 s\n",
      "Epoch: 104 Train_loss: 0.019 Val_acc: 0.901 Time consumed: 42.2880 s\n",
      "Epoch: 105 Train_loss: 0.052 Val_acc: 0.887 Time consumed: 42.2434 s\n",
      "Epoch: 106 Train_loss: 0.038 Val_acc: 0.897 Time consumed: 42.3586 s\n",
      "Epoch: 107 Train_loss: 0.033 Val_acc: 0.901 Time consumed: 42.3995 s\n",
      "Epoch: 108 Train_loss: 0.043 Val_acc: 0.888 Time consumed: 42.6421 s\n",
      "Epoch: 109 Train_loss: 0.021 Val_acc: 0.888 Time consumed: 42.5071 s\n",
      "Epoch: 110 Train_loss: 0.044 Val_acc: 0.897 Time consumed: 42.4956 s\n",
      "Epoch: 111 Train_loss: 0.045 Val_acc: 0.875 Time consumed: 42.6211 s\n",
      "Epoch: 112 Train_loss: 0.083 Val_acc: 0.901 Time consumed: 42.8813 s\n",
      "Epoch: 113 Train_loss: 0.027 Val_acc: 0.899 Time consumed: 42.5694 s\n",
      "Epoch: 114 Train_loss: 0.033 Val_acc: 0.897 Time consumed: 42.6421 s\n",
      "Epoch: 115 Train_loss: 0.006 Val_acc: 0.898 Time consumed: 42.5632 s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 116 Train_loss: 0.021 Val_acc: 0.896 Time consumed: 42.7422 s\n",
      "Epoch: 117 Train_loss: 0.007 Val_acc: 0.895 Time consumed: 42.6890 s\n",
      "Epoch: 118 Train_loss: 0.021 Val_acc: 0.896 Time consumed: 42.7358 s\n",
      "Epoch: 119 Train_loss: 0.064 Val_acc: 0.898 Time consumed: 42.6665 s\n",
      "Epoch: 120 Train_loss: 0.025 Val_acc: 0.898 Time consumed: 42.7063 s\n",
      "Epoch: 121 Train_loss: 0.067 Val_acc: 0.900 Time consumed: 42.7795 s\n",
      "Epoch: 122 Train_loss: 0.018 Val_acc: 0.904 Time consumed: 42.8459 s\n",
      "Epoch: 123 Train_loss: 0.028 Val_acc: 0.900 Time consumed: 42.9265 s\n",
      "Epoch: 124 Train_loss: 0.043 Val_acc: 0.881 Time consumed: 42.7497 s\n",
      "Epoch: 125 Train_loss: 0.026 Val_acc: 0.894 Time consumed: 42.8251 s\n",
      "Epoch: 126 Train_loss: 0.077 Val_acc: 0.895 Time consumed: 42.9737 s\n",
      "Epoch: 127 Train_loss: 0.027 Val_acc: 0.894 Time consumed: 42.8552 s\n",
      "Epoch: 128 Train_loss: 0.040 Val_acc: 0.902 Time consumed: 43.1856 s\n",
      "Epoch: 129 Train_loss: 0.011 Val_acc: 0.897 Time consumed: 43.2941 s\n",
      "Epoch: 130 Train_loss: 0.029 Val_acc: 0.892 Time consumed: 42.9841 s\n",
      "Epoch: 131 Train_loss: 0.066 Val_acc: 0.900 Time consumed: 43.0703 s\n",
      "Epoch: 132 Train_loss: 0.011 Val_acc: 0.896 Time consumed: 42.7681 s\n",
      "Epoch: 133 Train_loss: 0.032 Val_acc: 0.885 Time consumed: 43.0425 s\n",
      "Epoch: 134 Train_loss: 0.003 Val_acc: 0.901 Time consumed: 42.9603 s\n",
      "Epoch: 135 Train_loss: 0.033 Val_acc: 0.893 Time consumed: 43.1543 s\n",
      "Epoch: 136 Train_loss: 0.037 Val_acc: 0.905 Time consumed: 43.2122 s\n",
      "Epoch: 137 Train_loss: 0.002 Val_acc: 0.893 Time consumed: 42.3567 s\n",
      "Epoch: 138 Train_loss: 0.043 Val_acc: 0.892 Time consumed: 42.4925 s\n",
      "Epoch: 139 Train_loss: 0.046 Val_acc: 0.894 Time consumed: 42.3073 s\n",
      "Epoch: 140 Train_loss: 0.041 Val_acc: 0.896 Time consumed: 42.3676 s\n",
      "Epoch: 141 Train_loss: 0.011 Val_acc: 0.895 Time consumed: 42.3513 s\n",
      "Epoch: 142 Train_loss: 0.024 Val_acc: 0.900 Time consumed: 42.5067 s\n",
      "Epoch: 143 Train_loss: 0.003 Val_acc: 0.889 Time consumed: 42.4931 s\n",
      "Epoch: 144 Train_loss: 0.004 Val_acc: 0.899 Time consumed: 42.6960 s\n",
      "Epoch: 145 Train_loss: 0.008 Val_acc: 0.892 Time consumed: 42.4116 s\n",
      "Epoch: 146 Train_loss: 0.009 Val_acc: 0.902 Time consumed: 42.4594 s\n",
      "Epoch: 147 Train_loss: 0.019 Val_acc: 0.901 Time consumed: 42.7293 s\n",
      "Epoch: 148 Train_loss: 0.003 Val_acc: 0.894 Time consumed: 42.5468 s\n",
      "Epoch: 149 Train_loss: 0.019 Val_acc: 0.899 Time consumed: 42.6075 s\n",
      "Epoch: 150 Train_loss: 0.010 Val_acc: 0.888 Time consumed: 42.6013 s\n",
      "Epoch: 151 Train_loss: 0.030 Val_acc: 0.892 Time consumed: 42.6401 s\n",
      "Epoch: 152 Train_loss: 0.058 Val_acc: 0.900 Time consumed: 42.6583 s\n",
      "Epoch: 153 Train_loss: 0.016 Val_acc: 0.894 Time consumed: 42.8585 s\n",
      "Epoch: 154 Train_loss: 0.044 Val_acc: 0.891 Time consumed: 42.8190 s\n",
      "Epoch: 155 Train_loss: 0.010 Val_acc: 0.903 Time consumed: 43.1004 s\n",
      "Epoch: 156 Train_loss: 0.070 Val_acc: 0.904 Time consumed: 42.8131 s\n",
      "Epoch: 157 Train_loss: 0.008 Val_acc: 0.901 Time consumed: 43.0230 s\n",
      "Epoch: 158 Train_loss: 0.006 Val_acc: 0.888 Time consumed: 42.8735 s\n",
      "Epoch: 159 Train_loss: 0.049 Val_acc: 0.895 Time consumed: 42.9463 s\n",
      "Epoch: 160 Train_loss: 0.022 Val_acc: 0.899 Time consumed: 42.9036 s\n",
      "Epoch: 161 Train_loss: 0.006 Val_acc: 0.894 Time consumed: 42.8916 s\n",
      "Epoch: 162 Train_loss: 0.008 Val_acc: 0.900 Time consumed: 42.9014 s\n",
      "Epoch: 163 Train_loss: 0.019 Val_acc: 0.891 Time consumed: 42.4806 s\n",
      "Epoch: 164 Train_loss: 0.034 Val_acc: 0.904 Time consumed: 42.7097 s\n",
      "Epoch: 165 Train_loss: 0.032 Val_acc: 0.901 Time consumed: 43.0418 s\n",
      "Epoch: 166 Train_loss: 0.018 Val_acc: 0.901 Time consumed: 43.0130 s\n",
      "Epoch: 167 Train_loss: 0.001 Val_acc: 0.900 Time consumed: 43.0872 s\n",
      "Epoch: 168 Train_loss: 0.052 Val_acc: 0.895 Time consumed: 42.9755 s\n",
      "Epoch: 169 Train_loss: 0.006 Val_acc: 0.895 Time consumed: 42.9174 s\n",
      "Epoch: 170 Train_loss: 0.010 Val_acc: 0.899 Time consumed: 43.2574 s\n",
      "Epoch: 171 Train_loss: 0.002 Val_acc: 0.898 Time consumed: 42.3420 s\n",
      "Epoch: 172 Train_loss: 0.001 Val_acc: 0.901 Time consumed: 42.2455 s\n",
      "Epoch: 173 Train_loss: 0.001 Val_acc: 0.894 Time consumed: 42.5045 s\n",
      "Epoch: 174 Train_loss: 0.030 Val_acc: 0.892 Time consumed: 42.2310 s\n",
      "Epoch: 175 Train_loss: 0.014 Val_acc: 0.895 Time consumed: 42.4434 s\n",
      "Epoch: 176 Train_loss: 0.009 Val_acc: 0.894 Time consumed: 42.3265 s\n",
      "Epoch: 177 Train_loss: 0.014 Val_acc: 0.905 Time consumed: 42.4577 s\n",
      "Epoch: 178 Train_loss: 0.002 Val_acc: 0.896 Time consumed: 42.4831 s\n",
      "Epoch: 179 Train_loss: 0.005 Val_acc: 0.900 Time consumed: 42.6119 s\n",
      "Epoch: 180 Train_loss: 0.018 Val_acc: 0.896 Time consumed: 42.5945 s\n",
      "Epoch: 181 Train_loss: 0.020 Val_acc: 0.892 Time consumed: 42.5801 s\n",
      "Epoch: 182 Train_loss: 0.018 Val_acc: 0.902 Time consumed: 42.6704 s\n",
      "Epoch: 183 Train_loss: 0.001 Val_acc: 0.902 Time consumed: 42.5910 s\n",
      "Epoch: 184 Train_loss: 0.018 Val_acc: 0.898 Time consumed: 42.5543 s\n",
      "Epoch: 185 Train_loss: 0.002 Val_acc: 0.907 Time consumed: 43.7009 s\n",
      "Epoch: 186 Train_loss: 0.008 Val_acc: 0.892 Time consumed: 42.3261 s\n",
      "Epoch: 187 Train_loss: 0.043 Val_acc: 0.895 Time consumed: 42.3354 s\n",
      "Epoch: 188 Train_loss: 0.004 Val_acc: 0.898 Time consumed: 42.2739 s\n",
      "Epoch: 189 Train_loss: 0.034 Val_acc: 0.900 Time consumed: 42.3782 s\n",
      "Epoch: 190 Train_loss: 0.016 Val_acc: 0.907 Time consumed: 42.7527 s\n",
      "Epoch: 191 Train_loss: 0.007 Val_acc: 0.904 Time consumed: 42.4436 s\n",
      "Epoch: 192 Train_loss: 0.017 Val_acc: 0.907 Time consumed: 42.2822 s\n",
      "Epoch: 193 Train_loss: 0.018 Val_acc: 0.904 Time consumed: 42.3366 s\n",
      "Epoch: 194 Train_loss: 0.001 Val_acc: 0.904 Time consumed: 42.3408 s\n",
      "Epoch: 195 Train_loss: 0.008 Val_acc: 0.896 Time consumed: 42.2962 s\n",
      "Epoch: 196 Train_loss: 0.016 Val_acc: 0.899 Time consumed: 42.5199 s\n",
      "Epoch: 197 Train_loss: 0.003 Val_acc: 0.888 Time consumed: 42.3340 s\n",
      "Epoch: 198 Train_loss: 0.010 Val_acc: 0.899 Time consumed: 42.5189 s\n",
      "Epoch: 199 Train_loss: 0.019 Val_acc: 0.893 Time consumed: 42.4739 s\n",
      "Epoch: 200 Train_loss: 0.001 Val_acc: 0.904 Time consumed: 42.3057 s\n",
      "Epoch: 201 Train_loss: 0.005 Val_acc: 0.910 Time consumed: 43.3689 s\n",
      "Epoch: 202 Train_loss: 0.002 Val_acc: 0.898 Time consumed: 42.2804 s\n",
      "Epoch: 203 Train_loss: 0.001 Val_acc: 0.899 Time consumed: 42.1750 s\n",
      "Epoch: 204 Train_loss: 0.022 Val_acc: 0.905 Time consumed: 42.3991 s\n",
      "Epoch: 205 Train_loss: 0.002 Val_acc: 0.906 Time consumed: 42.3283 s\n",
      "Epoch: 206 Train_loss: 0.001 Val_acc: 0.902 Time consumed: 42.4049 s\n",
      "Epoch: 207 Train_loss: 0.006 Val_acc: 0.904 Time consumed: 42.6563 s\n",
      "Epoch: 208 Train_loss: 0.003 Val_acc: 0.897 Time consumed: 42.3824 s\n",
      "Epoch: 209 Train_loss: 0.039 Val_acc: 0.906 Time consumed: 42.5515 s\n",
      "Epoch: 210 Train_loss: 0.007 Val_acc: 0.896 Time consumed: 42.5825 s\n",
      "Epoch: 211 Train_loss: 0.032 Val_acc: 0.904 Time consumed: 42.6610 s\n",
      "Epoch: 212 Train_loss: 0.002 Val_acc: 0.896 Time consumed: 42.7525 s\n",
      "Epoch: 213 Train_loss: 0.047 Val_acc: 0.908 Time consumed: 42.6416 s\n",
      "Epoch: 214 Train_loss: 0.014 Val_acc: 0.904 Time consumed: 42.3570 s\n",
      "Epoch: 215 Train_loss: 0.013 Val_acc: 0.901 Time consumed: 42.6379 s\n",
      "Epoch: 216 Train_loss: 0.010 Val_acc: 0.898 Time consumed: 42.9475 s\n",
      "Epoch: 217 Train_loss: 0.008 Val_acc: 0.905 Time consumed: 42.6331 s\n",
      "Epoch: 218 Train_loss: 0.006 Val_acc: 0.902 Time consumed: 42.5523 s\n",
      "Epoch: 219 Train_loss: 0.036 Val_acc: 0.907 Time consumed: 42.7016 s\n",
      "Epoch: 220 Train_loss: 0.003 Val_acc: 0.903 Time consumed: 42.6866 s\n",
      "Epoch: 221 Train_loss: 0.023 Val_acc: 0.894 Time consumed: 42.7542 s\n",
      "Epoch: 222 Train_loss: 0.002 Val_acc: 0.904 Time consumed: 42.6899 s\n",
      "Epoch: 223 Train_loss: 0.002 Val_acc: 0.905 Time consumed: 42.9834 s\n",
      "Epoch: 224 Train_loss: 0.001 Val_acc: 0.903 Time consumed: 42.7324 s\n",
      "Epoch: 225 Train_loss: 0.003 Val_acc: 0.901 Time consumed: 42.7624 s\n",
      "Epoch: 226 Train_loss: 0.013 Val_acc: 0.903 Time consumed: 42.9732 s\n",
      "Epoch: 227 Train_loss: 0.046 Val_acc: 0.900 Time consumed: 42.8905 s\n",
      "Epoch: 228 Train_loss: 0.008 Val_acc: 0.905 Time consumed: 42.7152 s\n",
      "Epoch: 229 Train_loss: 0.008 Val_acc: 0.908 Time consumed: 42.9578 s\n",
      "Epoch: 230 Train_loss: 0.000 Val_acc: 0.902 Time consumed: 43.0214 s\n",
      "Epoch: 231 Train_loss: 0.005 Val_acc: 0.899 Time consumed: 42.8801 s\n",
      "Epoch: 232 Train_loss: 0.041 Val_acc: 0.897 Time consumed: 42.8415 s\n",
      "Epoch: 233 Train_loss: 0.022 Val_acc: 0.900 Time consumed: 42.9556 s\n",
      "Epoch: 234 Train_loss: 0.013 Val_acc: 0.906 Time consumed: 43.0322 s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 235 Train_loss: 0.000 Val_acc: 0.907 Time consumed: 42.6483 s\n",
      "Epoch: 236 Train_loss: 0.031 Val_acc: 0.904 Time consumed: 42.2038 s\n",
      "Epoch: 237 Train_loss: 0.003 Val_acc: 0.907 Time consumed: 42.1143 s\n",
      "Epoch: 238 Train_loss: 0.026 Val_acc: 0.906 Time consumed: 42.1934 s\n",
      "Epoch: 239 Train_loss: 0.047 Val_acc: 0.908 Time consumed: 42.2791 s\n",
      "Epoch: 240 Train_loss: 0.003 Val_acc: 0.912 Time consumed: 42.7892 s\n",
      "Epoch: 241 Train_loss: 0.001 Val_acc: 0.903 Time consumed: 42.1039 s\n",
      "Epoch: 242 Train_loss: 0.004 Val_acc: 0.900 Time consumed: 42.2578 s\n",
      "Epoch: 243 Train_loss: 0.003 Val_acc: 0.906 Time consumed: 42.3908 s\n",
      "Epoch: 244 Train_loss: 0.002 Val_acc: 0.904 Time consumed: 42.4003 s\n",
      "Epoch: 245 Train_loss: 0.014 Val_acc: 0.893 Time consumed: 42.3407 s\n",
      "Epoch: 246 Train_loss: 0.017 Val_acc: 0.904 Time consumed: 42.5908 s\n",
      "Epoch: 247 Train_loss: 0.001 Val_acc: 0.902 Time consumed: 42.6707 s\n",
      "Epoch: 248 Train_loss: 0.010 Val_acc: 0.899 Time consumed: 42.3805 s\n",
      "Epoch: 249 Train_loss: 0.002 Val_acc: 0.905 Time consumed: 42.8789 s\n",
      "Epoch: 250 Train_loss: 0.002 Val_acc: 0.906 Time consumed: 42.6395 s\n",
      "Epoch: 251 Train_loss: 0.002 Val_acc: 0.905 Time consumed: 42.6168 s\n",
      "Epoch: 252 Train_loss: 0.015 Val_acc: 0.902 Time consumed: 42.6555 s\n",
      "Epoch: 253 Train_loss: 0.002 Val_acc: 0.895 Time consumed: 42.5958 s\n",
      "Epoch: 254 Train_loss: 0.005 Val_acc: 0.901 Time consumed: 42.6900 s\n",
      "Epoch: 255 Train_loss: 0.011 Val_acc: 0.902 Time consumed: 42.7545 s\n",
      "Epoch: 256 Train_loss: 0.001 Val_acc: 0.903 Time consumed: 42.7024 s\n",
      "Epoch: 257 Train_loss: 0.002 Val_acc: 0.904 Time consumed: 42.8097 s\n",
      "Epoch: 258 Train_loss: 0.025 Val_acc: 0.900 Time consumed: 42.5661 s\n",
      "Epoch: 259 Train_loss: 0.001 Val_acc: 0.902 Time consumed: 42.6899 s\n",
      "Epoch: 260 Train_loss: 0.012 Val_acc: 0.897 Time consumed: 42.7131 s\n",
      "Epoch: 261 Train_loss: 0.001 Val_acc: 0.897 Time consumed: 42.7878 s\n",
      "Epoch: 262 Train_loss: 0.018 Val_acc: 0.901 Time consumed: 42.8571 s\n",
      "Epoch: 263 Train_loss: 0.009 Val_acc: 0.901 Time consumed: 42.6848 s\n",
      "Epoch: 264 Train_loss: 0.002 Val_acc: 0.909 Time consumed: 43.1183 s\n",
      "Epoch: 265 Train_loss: 0.009 Val_acc: 0.901 Time consumed: 43.0250 s\n",
      "Epoch: 266 Train_loss: 0.001 Val_acc: 0.904 Time consumed: 42.9166 s\n",
      "Epoch: 267 Train_loss: 0.005 Val_acc: 0.903 Time consumed: 42.6994 s\n",
      "Epoch: 268 Train_loss: 0.011 Val_acc: 0.903 Time consumed: 43.0375 s\n",
      "Epoch: 269 Train_loss: 0.002 Val_acc: 0.902 Time consumed: 42.5412 s\n",
      "Epoch: 270 Train_loss: 0.003 Val_acc: 0.907 Time consumed: 43.0283 s\n",
      "Epoch: 271 Train_loss: 0.007 Val_acc: 0.903 Time consumed: 42.8985 s\n",
      "Epoch: 272 Train_loss: 0.009 Val_acc: 0.904 Time consumed: 42.8701 s\n",
      "Epoch: 273 Train_loss: 0.002 Val_acc: 0.906 Time consumed: 42.8627 s\n",
      "Epoch: 274 Train_loss: 0.006 Val_acc: 0.907 Time consumed: 43.4570 s\n",
      "Epoch: 275 Train_loss: 0.003 Val_acc: 0.906 Time consumed: 42.4000 s\n",
      "Epoch: 276 Train_loss: 0.001 Val_acc: 0.908 Time consumed: 42.2193 s\n",
      "Epoch: 277 Train_loss: 0.020 Val_acc: 0.902 Time consumed: 42.5232 s\n",
      "Epoch: 278 Train_loss: 0.000 Val_acc: 0.906 Time consumed: 42.4181 s\n",
      "Epoch: 279 Train_loss: 0.001 Val_acc: 0.906 Time consumed: 42.3181 s\n",
      "Epoch: 280 Train_loss: 0.001 Val_acc: 0.908 Time consumed: 42.6045 s\n",
      "Epoch: 281 Train_loss: 0.002 Val_acc: 0.910 Time consumed: 42.7011 s\n",
      "Epoch: 282 Train_loss: 0.001 Val_acc: 0.906 Time consumed: 42.4982 s\n",
      "Epoch: 283 Train_loss: 0.000 Val_acc: 0.909 Time consumed: 42.6737 s\n",
      "Epoch: 284 Train_loss: 0.001 Val_acc: 0.908 Time consumed: 42.7104 s\n",
      "Epoch: 285 Train_loss: 0.002 Val_acc: 0.906 Time consumed: 42.5077 s\n",
      "Epoch: 286 Train_loss: 0.002 Val_acc: 0.908 Time consumed: 42.7998 s\n",
      "Epoch: 287 Train_loss: 0.030 Val_acc: 0.904 Time consumed: 42.7845 s\n",
      "Epoch: 288 Train_loss: 0.011 Val_acc: 0.906 Time consumed: 42.7569 s\n",
      "Epoch: 289 Train_loss: 0.003 Val_acc: 0.909 Time consumed: 42.6263 s\n",
      "Epoch: 290 Train_loss: 0.004 Val_acc: 0.905 Time consumed: 42.7506 s\n",
      "Epoch: 291 Train_loss: 0.001 Val_acc: 0.904 Time consumed: 42.6951 s\n",
      "Epoch: 292 Train_loss: 0.030 Val_acc: 0.905 Time consumed: 42.8649 s\n",
      "Epoch: 293 Train_loss: 0.006 Val_acc: 0.908 Time consumed: 42.7943 s\n",
      "Epoch: 294 Train_loss: 0.038 Val_acc: 0.906 Time consumed: 42.7572 s\n",
      "Epoch: 295 Train_loss: 0.004 Val_acc: 0.906 Time consumed: 42.7672 s\n",
      "Epoch: 296 Train_loss: 0.002 Val_acc: 0.908 Time consumed: 42.8180 s\n",
      "Epoch: 297 Train_loss: 0.000 Val_acc: 0.898 Time consumed: 42.8070 s\n",
      "Epoch: 298 Train_loss: 0.002 Val_acc: 0.905 Time consumed: 42.8058 s\n",
      "Epoch: 299 Train_loss: 0.001 Val_acc: 0.909 Time consumed: 42.7888 s\n",
      "Epoch: 300 Train_loss: 0.020 Val_acc: 0.904 Time consumed: 42.8712 s\n",
      "Epoch: 301 Train_loss: 0.000 Val_acc: 0.907 Time consumed: 42.7002 s\n",
      "Epoch: 302 Train_loss: 0.004 Val_acc: 0.907 Time consumed: 43.2527 s\n",
      "Epoch: 303 Train_loss: 0.000 Val_acc: 0.911 Time consumed: 43.1017 s\n",
      "Epoch: 304 Train_loss: 0.009 Val_acc: 0.908 Time consumed: 43.0570 s\n",
      "Epoch: 305 Train_loss: 0.004 Val_acc: 0.904 Time consumed: 42.8056 s\n",
      "Epoch: 306 Train_loss: 0.002 Val_acc: 0.907 Time consumed: 43.3449 s\n",
      "Epoch: 307 Train_loss: 0.001 Val_acc: 0.909 Time consumed: 43.0841 s\n",
      "Epoch: 308 Train_loss: 0.001 Val_acc: 0.911 Time consumed: 43.4124 s\n",
      "Epoch: 309 Train_loss: 0.001 Val_acc: 0.906 Time consumed: 42.1673 s\n",
      "Epoch: 310 Train_loss: 0.026 Val_acc: 0.908 Time consumed: 42.2790 s\n",
      "Epoch: 311 Train_loss: 0.001 Val_acc: 0.908 Time consumed: 42.4468 s\n",
      "Epoch: 312 Train_loss: 0.000 Val_acc: 0.907 Time consumed: 42.5573 s\n",
      "Epoch: 313 Train_loss: 0.000 Val_acc: 0.906 Time consumed: 42.5975 s\n",
      "Epoch: 314 Train_loss: 0.009 Val_acc: 0.910 Time consumed: 42.5683 s\n",
      "Epoch: 315 Train_loss: 0.001 Val_acc: 0.905 Time consumed: 42.5340 s\n",
      "Epoch: 316 Train_loss: 0.000 Val_acc: 0.911 Time consumed: 42.5266 s\n",
      "Epoch: 317 Train_loss: 0.000 Val_acc: 0.907 Time consumed: 42.6660 s\n",
      "Epoch: 318 Train_loss: 0.003 Val_acc: 0.909 Time consumed: 42.5889 s\n",
      "Epoch: 319 Train_loss: 0.000 Val_acc: 0.908 Time consumed: 42.8772 s\n",
      "Epoch: 320 Train_loss: 0.001 Val_acc: 0.907 Time consumed: 42.7610 s\n",
      "Epoch: 321 Train_loss: 0.003 Val_acc: 0.905 Time consumed: 42.8615 s\n",
      "Epoch: 322 Train_loss: 0.000 Val_acc: 0.905 Time consumed: 42.7105 s\n",
      "Epoch: 323 Train_loss: 0.000 Val_acc: 0.907 Time consumed: 42.9001 s\n",
      "Epoch: 324 Train_loss: 0.011 Val_acc: 0.904 Time consumed: 42.8315 s\n",
      "Epoch: 325 Train_loss: 0.023 Val_acc: 0.913 Time consumed: 43.6763 s\n",
      "Epoch: 326 Train_loss: 0.001 Val_acc: 0.905 Time consumed: 42.4093 s\n",
      "Epoch: 327 Train_loss: 0.000 Val_acc: 0.906 Time consumed: 42.1571 s\n",
      "Epoch: 328 Train_loss: 0.004 Val_acc: 0.905 Time consumed: 42.3474 s\n",
      "Epoch: 329 Train_loss: 0.019 Val_acc: 0.906 Time consumed: 42.3671 s\n",
      "Epoch: 330 Train_loss: 0.003 Val_acc: 0.905 Time consumed: 42.4462 s\n",
      "Epoch: 331 Train_loss: 0.002 Val_acc: 0.904 Time consumed: 42.2659 s\n",
      "Epoch: 332 Train_loss: 0.007 Val_acc: 0.908 Time consumed: 42.6364 s\n",
      "Epoch: 333 Train_loss: 0.007 Val_acc: 0.909 Time consumed: 42.4164 s\n",
      "Epoch: 334 Train_loss: 0.002 Val_acc: 0.904 Time consumed: 42.6375 s\n",
      "Epoch: 335 Train_loss: 0.005 Val_acc: 0.912 Time consumed: 42.6882 s\n",
      "Epoch: 336 Train_loss: 0.001 Val_acc: 0.909 Time consumed: 42.7131 s\n",
      "Epoch: 337 Train_loss: 0.001 Val_acc: 0.907 Time consumed: 42.6601 s\n",
      "Epoch: 338 Train_loss: 0.000 Val_acc: 0.906 Time consumed: 42.9112 s\n",
      "Epoch: 339 Train_loss: 0.001 Val_acc: 0.905 Time consumed: 42.7694 s\n",
      "Epoch: 340 Train_loss: 0.000 Val_acc: 0.904 Time consumed: 42.8500 s\n",
      "Epoch: 341 Train_loss: 0.000 Val_acc: 0.908 Time consumed: 42.6014 s\n",
      "Epoch: 342 Train_loss: 0.001 Val_acc: 0.911 Time consumed: 42.8926 s\n",
      "Epoch: 343 Train_loss: 0.001 Val_acc: 0.910 Time consumed: 42.7642 s\n",
      "Epoch: 344 Train_loss: 0.005 Val_acc: 0.901 Time consumed: 42.7875 s\n",
      "Epoch: 345 Train_loss: 0.001 Val_acc: 0.908 Time consumed: 42.8438 s\n",
      "Epoch: 346 Train_loss: 0.010 Val_acc: 0.903 Time consumed: 43.0638 s\n",
      "Epoch: 347 Train_loss: 0.001 Val_acc: 0.912 Time consumed: 43.0853 s\n",
      "Epoch: 348 Train_loss: 0.003 Val_acc: 0.913 Time consumed: 43.0342 s\n",
      "Epoch: 349 Train_loss: 0.000 Val_acc: 0.910 Time consumed: 42.7242 s\n",
      "Epoch: 350 Train_loss: 0.003 Val_acc: 0.912 Time consumed: 42.7977 s\n",
      "Epoch: 351 Train_loss: 0.017 Val_acc: 0.909 Time consumed: 43.2501 s\n",
      "Epoch: 352 Train_loss: 0.002 Val_acc: 0.910 Time consumed: 43.1668 s\n",
      "Epoch: 353 Train_loss: 0.003 Val_acc: 0.910 Time consumed: 43.0494 s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 354 Train_loss: 0.000 Val_acc: 0.906 Time consumed: 42.9874 s\n",
      "Epoch: 355 Train_loss: 0.007 Val_acc: 0.906 Time consumed: 42.8278 s\n",
      "Epoch: 356 Train_loss: 0.001 Val_acc: 0.907 Time consumed: 43.1934 s\n",
      "Epoch: 357 Train_loss: 0.002 Val_acc: 0.912 Time consumed: 43.0802 s\n",
      "Epoch: 358 Train_loss: 0.000 Val_acc: 0.908 Time consumed: 43.0193 s\n",
      "Epoch: 359 Train_loss: 0.002 Val_acc: 0.912 Time consumed: 42.9729 s\n",
      "Epoch: 360 Train_loss: 0.003 Val_acc: 0.910 Time consumed: 42.5491 s\n",
      "Epoch: 361 Train_loss: 0.000 Val_acc: 0.908 Time consumed: 42.1867 s\n",
      "Epoch: 362 Train_loss: 0.006 Val_acc: 0.906 Time consumed: 42.4442 s\n",
      "Epoch: 363 Train_loss: 0.001 Val_acc: 0.907 Time consumed: 42.5579 s\n",
      "Epoch: 364 Train_loss: 0.001 Val_acc: 0.913 Time consumed: 42.5421 s\n",
      "Epoch: 365 Train_loss: 0.000 Val_acc: 0.908 Time consumed: 42.7057 s\n",
      "Epoch: 366 Train_loss: 0.001 Val_acc: 0.912 Time consumed: 42.5941 s\n",
      "Epoch: 367 Train_loss: 0.004 Val_acc: 0.909 Time consumed: 42.4517 s\n",
      "Epoch: 368 Train_loss: 0.005 Val_acc: 0.908 Time consumed: 42.7056 s\n",
      "Epoch: 369 Train_loss: 0.006 Val_acc: 0.909 Time consumed: 42.6347 s\n",
      "Epoch: 370 Train_loss: 0.000 Val_acc: 0.913 Time consumed: 42.4033 s\n",
      "Epoch: 371 Train_loss: 0.023 Val_acc: 0.907 Time consumed: 42.8033 s\n",
      "Epoch: 372 Train_loss: 0.001 Val_acc: 0.913 Time consumed: 42.6433 s\n",
      "Epoch: 373 Train_loss: 0.007 Val_acc: 0.909 Time consumed: 42.8170 s\n",
      "Epoch: 374 Train_loss: 0.005 Val_acc: 0.912 Time consumed: 42.9675 s\n",
      "Epoch: 375 Train_loss: 0.011 Val_acc: 0.908 Time consumed: 42.6037 s\n",
      "Epoch: 376 Train_loss: 0.005 Val_acc: 0.908 Time consumed: 42.9849 s\n",
      "Epoch: 377 Train_loss: 0.006 Val_acc: 0.909 Time consumed: 42.8303 s\n",
      "Epoch: 378 Train_loss: 0.001 Val_acc: 0.912 Time consumed: 42.8604 s\n",
      "Epoch: 379 Train_loss: 0.000 Val_acc: 0.910 Time consumed: 42.9610 s\n",
      "Epoch: 380 Train_loss: 0.047 Val_acc: 0.912 Time consumed: 42.5988 s\n",
      "Epoch: 381 Train_loss: 0.002 Val_acc: 0.909 Time consumed: 43.0028 s\n",
      "Epoch: 382 Train_loss: 0.001 Val_acc: 0.910 Time consumed: 42.7966 s\n",
      "Epoch: 383 Train_loss: 0.044 Val_acc: 0.906 Time consumed: 43.0644 s\n",
      "Epoch: 384 Train_loss: 0.001 Val_acc: 0.903 Time consumed: 42.8239 s\n",
      "Epoch: 385 Train_loss: 0.002 Val_acc: 0.904 Time consumed: 42.8803 s\n",
      "Epoch: 386 Train_loss: 0.001 Val_acc: 0.908 Time consumed: 42.9554 s\n",
      "Epoch: 387 Train_loss: 0.000 Val_acc: 0.910 Time consumed: 42.9590 s\n",
      "Epoch: 388 Train_loss: 0.000 Val_acc: 0.909 Time consumed: 42.8414 s\n",
      "Epoch: 389 Train_loss: 0.000 Val_acc: 0.915 Time consumed: 44.1830 s\n",
      "Epoch: 390 Train_loss: 0.000 Val_acc: 0.911 Time consumed: 42.3767 s\n",
      "Epoch: 391 Train_loss: 0.000 Val_acc: 0.911 Time consumed: 42.3742 s\n",
      "Epoch: 392 Train_loss: 0.001 Val_acc: 0.911 Time consumed: 42.5837 s\n",
      "Epoch: 393 Train_loss: 0.000 Val_acc: 0.908 Time consumed: 42.2973 s\n",
      "Epoch: 394 Train_loss: 0.004 Val_acc: 0.909 Time consumed: 42.4986 s\n",
      "Epoch: 395 Train_loss: 0.001 Val_acc: 0.906 Time consumed: 42.5620 s\n",
      "Epoch: 396 Train_loss: 0.000 Val_acc: 0.911 Time consumed: 42.6268 s\n",
      "Epoch: 397 Train_loss: 0.000 Val_acc: 0.909 Time consumed: 42.8322 s\n",
      "Epoch: 398 Train_loss: 0.011 Val_acc: 0.907 Time consumed: 42.8149 s\n",
      "Epoch: 399 Train_loss: 0.003 Val_acc: 0.913 Time consumed: 42.5613 s\n",
      "Epoch: 400 Train_loss: 0.000 Val_acc: 0.912 Time consumed: 42.7768 s\n",
      "Epoch: 401 Train_loss: 0.000 Val_acc: 0.913 Time consumed: 42.7629 s\n",
      "Epoch: 402 Train_loss: 0.002 Val_acc: 0.907 Time consumed: 42.7628 s\n",
      "Epoch: 403 Train_loss: 0.001 Val_acc: 0.909 Time consumed: 42.7331 s\n",
      "Epoch: 404 Train_loss: 0.000 Val_acc: 0.911 Time consumed: 42.7326 s\n",
      "Epoch: 405 Train_loss: 0.000 Val_acc: 0.910 Time consumed: 42.9026 s\n",
      "Epoch: 406 Train_loss: 0.000 Val_acc: 0.911 Time consumed: 42.9983 s\n",
      "Epoch: 407 Train_loss: 0.002 Val_acc: 0.909 Time consumed: 42.9730 s\n",
      "Epoch: 408 Train_loss: 0.003 Val_acc: 0.907 Time consumed: 42.8755 s\n",
      "Epoch: 409 Train_loss: 0.000 Val_acc: 0.908 Time consumed: 42.9545 s\n",
      "Epoch: 410 Train_loss: 0.000 Val_acc: 0.906 Time consumed: 42.8501 s\n",
      "Epoch: 411 Train_loss: 0.010 Val_acc: 0.905 Time consumed: 42.9833 s\n",
      "Epoch: 412 Train_loss: 0.001 Val_acc: 0.910 Time consumed: 43.0858 s\n",
      "Epoch: 413 Train_loss: 0.006 Val_acc: 0.911 Time consumed: 42.9597 s\n",
      "Epoch: 414 Train_loss: 0.000 Val_acc: 0.909 Time consumed: 42.9516 s\n",
      "Epoch: 415 Train_loss: 0.000 Val_acc: 0.910 Time consumed: 43.1881 s\n",
      "Epoch: 416 Train_loss: 0.001 Val_acc: 0.908 Time consumed: 43.0070 s\n",
      "Epoch: 417 Train_loss: 0.005 Val_acc: 0.909 Time consumed: 43.0212 s\n",
      "Epoch: 418 Train_loss: 0.001 Val_acc: 0.914 Time consumed: 43.1778 s\n",
      "Epoch: 419 Train_loss: 0.008 Val_acc: 0.908 Time consumed: 43.0620 s\n",
      "Epoch: 420 Train_loss: 0.002 Val_acc: 0.911 Time consumed: 43.1270 s\n",
      "Epoch: 421 Train_loss: 0.001 Val_acc: 0.907 Time consumed: 43.1299 s\n",
      "Epoch: 422 Train_loss: 0.001 Val_acc: 0.909 Time consumed: 42.9943 s\n",
      "Epoch: 423 Train_loss: 0.000 Val_acc: 0.905 Time consumed: 43.1023 s\n",
      "Epoch: 424 Train_loss: 0.001 Val_acc: 0.912 Time consumed: 43.4461 s\n",
      "Epoch: 425 Train_loss: 0.000 Val_acc: 0.912 Time consumed: 42.4950 s\n",
      "Epoch: 426 Train_loss: 0.001 Val_acc: 0.915 Time consumed: 42.8983 s\n",
      "Epoch: 427 Train_loss: 0.001 Val_acc: 0.914 Time consumed: 42.2549 s\n",
      "Epoch: 428 Train_loss: 0.002 Val_acc: 0.912 Time consumed: 42.4425 s\n",
      "Epoch: 429 Train_loss: 0.000 Val_acc: 0.912 Time consumed: 42.2910 s\n",
      "Epoch: 430 Train_loss: 0.002 Val_acc: 0.906 Time consumed: 42.5631 s\n",
      "Epoch: 431 Train_loss: 0.000 Val_acc: 0.908 Time consumed: 42.6826 s\n",
      "Epoch: 432 Train_loss: 0.000 Val_acc: 0.910 Time consumed: 42.6540 s\n",
      "Epoch: 433 Train_loss: 0.000 Val_acc: 0.913 Time consumed: 42.6046 s\n",
      "Epoch: 434 Train_loss: 0.000 Val_acc: 0.912 Time consumed: 42.6361 s\n",
      "Epoch: 435 Train_loss: 0.003 Val_acc: 0.906 Time consumed: 42.6060 s\n",
      "Epoch: 436 Train_loss: 0.000 Val_acc: 0.912 Time consumed: 42.8785 s\n",
      "Epoch: 437 Train_loss: 0.000 Val_acc: 0.913 Time consumed: 42.7816 s\n",
      "Epoch: 438 Train_loss: 0.000 Val_acc: 0.908 Time consumed: 42.8281 s\n",
      "Epoch: 439 Train_loss: 0.012 Val_acc: 0.915 Time consumed: 43.3721 s\n",
      "Epoch: 440 Train_loss: 0.000 Val_acc: 0.912 Time consumed: 42.3287 s\n",
      "Epoch: 441 Train_loss: 0.000 Val_acc: 0.910 Time consumed: 42.4084 s\n",
      "Epoch: 442 Train_loss: 0.001 Val_acc: 0.909 Time consumed: 42.4684 s\n",
      "Epoch: 443 Train_loss: 0.001 Val_acc: 0.909 Time consumed: 42.5333 s\n",
      "Epoch: 444 Train_loss: 0.000 Val_acc: 0.912 Time consumed: 42.3177 s\n",
      "Epoch: 445 Train_loss: 0.000 Val_acc: 0.910 Time consumed: 42.4567 s\n",
      "Epoch: 446 Train_loss: 0.006 Val_acc: 0.913 Time consumed: 42.5816 s\n",
      "Epoch: 447 Train_loss: 0.000 Val_acc: 0.911 Time consumed: 42.5937 s\n",
      "Epoch: 448 Train_loss: 0.001 Val_acc: 0.911 Time consumed: 42.7076 s\n",
      "Epoch: 449 Train_loss: 0.019 Val_acc: 0.912 Time consumed: 42.7965 s\n",
      "Epoch: 450 Train_loss: 0.000 Val_acc: 0.909 Time consumed: 42.5070 s\n",
      "Epoch: 451 Train_loss: 0.000 Val_acc: 0.912 Time consumed: 42.6759 s\n",
      "Epoch: 452 Train_loss: 0.000 Val_acc: 0.909 Time consumed: 43.0038 s\n",
      "Epoch: 453 Train_loss: 0.002 Val_acc: 0.907 Time consumed: 42.8857 s\n",
      "Epoch: 454 Train_loss: 0.029 Val_acc: 0.909 Time consumed: 42.9438 s\n",
      "Epoch: 455 Train_loss: 0.000 Val_acc: 0.909 Time consumed: 42.8392 s\n",
      "Epoch: 456 Train_loss: 0.002 Val_acc: 0.911 Time consumed: 42.7316 s\n",
      "Epoch: 457 Train_loss: 0.001 Val_acc: 0.914 Time consumed: 42.9323 s\n",
      "Epoch: 458 Train_loss: 0.003 Val_acc: 0.913 Time consumed: 42.8766 s\n",
      "Epoch: 459 Train_loss: 0.020 Val_acc: 0.912 Time consumed: 43.2127 s\n",
      "Epoch: 460 Train_loss: 0.001 Val_acc: 0.910 Time consumed: 43.1376 s\n",
      "Epoch: 461 Train_loss: 0.001 Val_acc: 0.910 Time consumed: 42.7737 s\n",
      "Epoch: 462 Train_loss: 0.002 Val_acc: 0.909 Time consumed: 43.0374 s\n",
      "Epoch: 463 Train_loss: 0.000 Val_acc: 0.909 Time consumed: 43.0320 s\n",
      "Epoch: 464 Train_loss: 0.000 Val_acc: 0.911 Time consumed: 42.9700 s\n",
      "Epoch: 465 Train_loss: 0.001 Val_acc: 0.912 Time consumed: 42.9836 s\n",
      "Epoch: 466 Train_loss: 0.000 Val_acc: 0.912 Time consumed: 42.7496 s\n",
      "Epoch: 467 Train_loss: 0.001 Val_acc: 0.915 Time consumed: 44.0309 s\n",
      "Epoch: 468 Train_loss: 0.009 Val_acc: 0.909 Time consumed: 42.4287 s\n",
      "Epoch: 469 Train_loss: 0.002 Val_acc: 0.912 Time consumed: 42.3065 s\n",
      "Epoch: 470 Train_loss: 0.000 Val_acc: 0.913 Time consumed: 42.5291 s\n",
      "Epoch: 471 Train_loss: 0.002 Val_acc: 0.910 Time consumed: 42.3480 s\n",
      "Epoch: 472 Train_loss: 0.000 Val_acc: 0.908 Time consumed: 42.4119 s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 473 Train_loss: 0.001 Val_acc: 0.908 Time consumed: 42.7114 s\n",
      "Epoch: 474 Train_loss: 0.000 Val_acc: 0.908 Time consumed: 42.5490 s\n",
      "Epoch: 475 Train_loss: 0.000 Val_acc: 0.912 Time consumed: 42.7678 s\n",
      "Epoch: 476 Train_loss: 0.000 Val_acc: 0.912 Time consumed: 42.7412 s\n",
      "Epoch: 477 Train_loss: 0.010 Val_acc: 0.911 Time consumed: 42.9329 s\n",
      "Epoch: 478 Train_loss: 0.001 Val_acc: 0.911 Time consumed: 42.8113 s\n",
      "Epoch: 479 Train_loss: 0.002 Val_acc: 0.915 Time consumed: 42.9170 s\n",
      "Epoch: 480 Train_loss: 0.000 Val_acc: 0.909 Time consumed: 42.7351 s\n",
      "Epoch: 481 Train_loss: 0.000 Val_acc: 0.910 Time consumed: 42.9240 s\n",
      "Epoch: 482 Train_loss: 0.000 Val_acc: 0.912 Time consumed: 42.8970 s\n",
      "Epoch: 483 Train_loss: 0.005 Val_acc: 0.910 Time consumed: 42.9912 s\n",
      "Epoch: 484 Train_loss: 0.000 Val_acc: 0.908 Time consumed: 42.6963 s\n",
      "Epoch: 485 Train_loss: 0.000 Val_acc: 0.910 Time consumed: 43.0008 s\n",
      "Epoch: 486 Train_loss: 0.004 Val_acc: 0.913 Time consumed: 42.8651 s\n",
      "Epoch: 487 Train_loss: 0.007 Val_acc: 0.911 Time consumed: 43.0552 s\n",
      "Epoch: 488 Train_loss: 0.001 Val_acc: 0.916 Time consumed: 43.8215 s\n",
      "Epoch: 489 Train_loss: 0.001 Val_acc: 0.909 Time consumed: 42.3694 s\n",
      "Epoch: 490 Train_loss: 0.000 Val_acc: 0.913 Time consumed: 42.4578 s\n",
      "Epoch: 491 Train_loss: 0.000 Val_acc: 0.908 Time consumed: 42.2713 s\n",
      "Epoch: 492 Train_loss: 0.000 Val_acc: 0.912 Time consumed: 42.6319 s\n",
      "Epoch: 493 Train_loss: 0.000 Val_acc: 0.909 Time consumed: 42.3141 s\n",
      "Epoch: 494 Train_loss: 0.000 Val_acc: 0.912 Time consumed: 42.6309 s\n",
      "Epoch: 495 Train_loss: 0.001 Val_acc: 0.910 Time consumed: 42.5241 s\n",
      "Epoch: 496 Train_loss: 0.000 Val_acc: 0.908 Time consumed: 42.6568 s\n",
      "Epoch: 497 Train_loss: 0.000 Val_acc: 0.911 Time consumed: 42.5515 s\n",
      "Epoch: 498 Train_loss: 0.000 Val_acc: 0.911 Time consumed: 42.7317 s\n",
      "Epoch: 499 Train_loss: 0.000 Val_acc: 0.912 Time consumed: 42.8393 s\n",
      "Epoch: 500 Train_loss: 0.001 Val_acc: 0.912 Time consumed: 42.9185 s\n",
      "*****************Training End!*****************\n"
     ]
    }
   ],
   "source": [
    "config = tf.ConfigProto(allow_soft_placement=True,\n",
    "                        log_device_placement=True)\n",
    "config.gpu_options.allow_growth = True\n",
    "\n",
    "with tf.Session(config=config) as sess:\n",
    "\n",
    "    print('*****************Training Start!*****************')\n",
    "    train_writer = tf.summary.FileWriter(save_dir+'train', sess.graph)\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "\n",
    "    for m in range(epochs):\n",
    "        start = time.time()\n",
    "        batch_gen = datagen.flow(\n",
    "            x_train, y_train, batch_size=batch_size)\n",
    "\n",
    "        for i in range(iterations):\n",
    "            x_batch, y_batch = next(batch_gen)\n",
    "            _, loss_train = sess.run([train_op, loss], \n",
    "                                     {inputs: x_batch, outputs: y_batch, is_train: True})\n",
    "        \n",
    "        summary = sess.run(merged, {inputs: x_batch, outputs: y_batch, is_train: False})\n",
    "        train_writer.add_summary(summary, m*iterations + i + 1)\n",
    "\n",
    "        val_accs = []\n",
    "        for i in range(5000//(batch_size*5)):\n",
    "            val_acc = sess.run(accuracy, {inputs: x_test[i*batch_size*5: (i+1)*batch_size*5],\n",
    "                                          outputs: y_test[i*batch_size*5: (i+1)*batch_size*5],\n",
    "                                          is_train: False})\n",
    "            val_accs.append(val_acc)\n",
    "\n",
    "        if np.mean(val_accs) > old_acc:\n",
    "            old_acc = np.mean(val_accs)\n",
    "            saver.save(sess, save_dir+'cifar10.ckpt', global_step=global_step)\n",
    "\n",
    "        end = time.time()\n",
    "        print('Epoch: {}'.format(m + 1),\n",
    "              'Train_loss: {:.3f}'.format(loss_train),\n",
    "              'Val_acc: {:.3f}'.format(np.mean(val_accs)),\n",
    "              'Time consumed: {:.4f} s'.format(end - start))\n",
    "\n",
    "    print('*****************Training End!*****************')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
