{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !rm -rf ./wide_resnet_poly_2ndtrain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%config IPCompleter.greedy=True\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run ./datagen.py\n",
    "datagen, (x_train, y_train), (x_test, y_test) = data_preparation()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_dir = './wide_resnet_poly_10_2ndtrain/'\n",
    "batch_size = 100\n",
    "iterations = x_train.shape[0] // batch_size\n",
    "epochs = 1000\n",
    "old_acc = 0\n",
    "start_lr = 1e-5\n",
    "end_lr = 1e-6\n",
    "decay_rate = (end_lr / start_lr) ** (1 / epochs)\n",
    "k = 10\n",
    "# regularizer = tf.contrib.layers.l2_regularizer(scale=1e-4)\n",
    "# initializer=tf.initializers.he_normal()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def act(x, i):\n",
    "    \n",
    "    # ax^2 + bx + c\n",
    "        \n",
    "    if i == 1:\n",
    "        first_coef = tf.Variable(0.31931543, trainable=True, name='first_coef', dtype=tf.float32)\n",
    "        second_coef = tf.Variable(0.49708712, trainable=True, name='second_coef', dtype=tf.float32)\n",
    "        third_coef = tf.Variable(0.12422738, trainable=True, name='third_coef', dtype=tf.float32)\n",
    "        y = tf.math.polyval([first_coef, second_coef, third_coef], x)\n",
    "        \n",
    "    elif i == 2:\n",
    "        first_coef = tf.Variable(0.14951853, trainable=True, name='first_coef', dtype=tf.float32)\n",
    "        second_coef = tf.Variable(0.49850001, trainable=True, name='second_coef', dtype=tf.float32)\n",
    "        third_coef = tf.Variable(0.26582837, trainable=True, name='third_coef', dtype=tf.float32)\n",
    "        y = tf.math.polyval([first_coef, second_coef, third_coef], x)\n",
    "        \n",
    "    elif i == 3:\n",
    "        first_coef = tf.Variable(0.16431344, trainable=True, name='first_coef', dtype=tf.float32)\n",
    "        second_coef = tf.Variable(0.48894203, trainable=True, name='second_coef', dtype=tf.float32)\n",
    "        third_coef = tf.Variable(0.23802768, trainable=True, name='third_coef', dtype=tf.float32)\n",
    "        y = tf.math.polyval([first_coef, second_coef, third_coef], x)\n",
    "\n",
    "    elif i == 4:\n",
    "        first_coef = tf.Variable(0.14941755, trainable=True, name='first_coef', dtype=tf.float32)\n",
    "        second_coef = tf.Variable(0.48750084, trainable=True, name='second_coef', dtype=tf.float32)\n",
    "        third_coef = tf.Variable(0.26098495, trainable=True, name='third_coef', dtype=tf.float32)\n",
    "        y = tf.math.polyval([first_coef, second_coef, third_coef], x)\n",
    "\n",
    "    elif i == 5:\n",
    "        first_coef = tf.Variable(0.10792727, trainable=True, name='first_coef', dtype=tf.float32)\n",
    "        second_coef = tf.Variable(0.48113492, trainable=True, name='second_coef', dtype=tf.float32)\n",
    "        third_coef = tf.Variable(0.35588625, trainable=True, name='third_coef', dtype=tf.float32)\n",
    "        y = tf.math.polyval([first_coef, second_coef, third_coef], x)\n",
    "\n",
    "    else:\n",
    "        first_coef = tf.Variable(0.07860769, trainable=True, name='first_coef', dtype=tf.float32)\n",
    "        second_coef = tf.Variable(0.49907132, trainable=True, name='second_coef', dtype=tf.float32)\n",
    "        third_coef = tf.Variable(0.50563614, trainable=True, name='third_coef', dtype=tf.float32)\n",
    "        y = tf.math.polyval([first_coef, second_coef, third_coef], x)\n",
    "\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# resnet layer\n",
    "def res_layer(inputs, filter_num, filter_size, stride, is_train, act_num, \n",
    "              batch_norm=True, activation=True):\n",
    "\n",
    "    x = inputs\n",
    "\n",
    "    if batch_norm:\n",
    "        x = tf.layers.batch_normalization(x, training=is_train)\n",
    "    if activation:\n",
    "        x = act(x, act_num)\n",
    "    x = tf.layers.conv2d(inputs=x, filters=filter_num, \n",
    "                         kernel_size=filter_size, strides=stride, padding='same')\n",
    "        \n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def wide_resnet(inputs, k, is_train):\n",
    "\n",
    "    with tf.variable_scope(\"1st_Conv\"):\n",
    "        x = tf.layers.conv2d(inputs=inputs, filters=16, \n",
    "                             kernel_size=3, strides=1, padding='same')\n",
    "        x = tf.layers.batch_normalization(x, training=is_train)\n",
    "        x = tf.nn.relu(x)\n",
    "        tf.summary.histogram('activation', x)\n",
    "\n",
    "    # Res Blocks\n",
    "    a = [1, 1, 1]\n",
    "    act_num = 0\n",
    "\n",
    "    for stack in range(len(a)):\n",
    "        for block in range(a[stack]):\n",
    "\n",
    "            with tf.variable_scope('ResBlock_%d_%d' % (stack+1, block+1)):\n",
    "\n",
    "                batch_norm = True\n",
    "                activation = True\n",
    "                stride = 1\n",
    "                filter_num = 16*k*(2**stack)\n",
    "                if stack == 0:\n",
    "                    if block == 0:\n",
    "                        batch_norm = False\n",
    "                        activation = False\n",
    "                else:  \n",
    "                    if block == 0:\n",
    "                        stride = 2\n",
    "\n",
    "                shortcut = x\n",
    "                with tf.variable_scope('conv1'):\n",
    "                    x = res_layer(x, filter_num, 3, stride, is_train, act_num, \n",
    "                                  batch_norm=batch_norm, activation=activation)\n",
    "                    act_num += 1\n",
    "                    \n",
    "                x = tf.layers.dropout(x, 0.1)\n",
    "                \n",
    "                with tf.variable_scope('conv2'):\n",
    "                    x = res_layer(x, filter_num, 3, 1, is_train, act_num)\n",
    "                    act_num += 1\n",
    "                \n",
    "                with tf.variable_scope('x_plus_shortcut'):\n",
    "                    if block == 0:\n",
    "                        shortcut = tf.layers.conv2d(inputs=shortcut, filters=filter_num, \n",
    "                                                    kernel_size=1, strides=stride, \n",
    "                                                    padding='same')\n",
    "                    x = x + shortcut\n",
    "                tf.summary.histogram('output', x)\n",
    "    \n",
    "    with tf.variable_scope(\"AfterResBlock\"):\n",
    "        x = tf.layers.batch_normalization(x, training=is_train)\n",
    "        x = act(x, act_num)\n",
    "        x = tf.layers.average_pooling2d(x, pool_size=8, strides=8, \n",
    "                                        padding='SAME', name='ave_pool')\n",
    "        tf.summary.histogram('output', x)\n",
    "        \n",
    "    with tf.variable_scope(\"Flatten\"):\n",
    "        x = tf.transpose(x, perm=[0, 3, 1, 2])\n",
    "        x = tf.layers.flatten(x)\n",
    "    \n",
    "    # crrent x.shape = (?, 256)\n",
    "    with tf.variable_scope(\"Prediction\"):\n",
    "        pred = tf.layers.dense(x, units=10)\n",
    "        tf.summary.histogram('output', x)\n",
    "        \n",
    "    return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From <ipython-input-7-9d75e0e7642f>:5: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.conv2d instead.\n",
      "WARNING:tensorflow:From <ipython-input-7-9d75e0e7642f>:6: batch_normalization (from tensorflow.python.layers.normalization) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.batch_normalization instead.\n",
      "WARNING:tensorflow:From <ipython-input-7-9d75e0e7642f>:37: dropout (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.dropout instead.\n",
      "WARNING:tensorflow:From <ipython-input-7-9d75e0e7642f>:55: average_pooling2d (from tensorflow.python.layers.pooling) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.average_pooling2d instead.\n",
      "WARNING:tensorflow:From <ipython-input-7-9d75e0e7642f>:60: flatten (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.flatten instead.\n",
      "WARNING:tensorflow:From <ipython-input-7-9d75e0e7642f>:64: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.dense instead.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/losses/losses_impl.py:209: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"7\"\n",
    "\n",
    "tf.reset_default_graph()\n",
    "\n",
    "with tf.device('/GPU:7'):\n",
    "\n",
    "    inputs = tf.placeholder(tf.float32, [None, 32, 32, 3], name='input')\n",
    "    outputs = tf.placeholder(tf.float32, [None, 10], name='output')\n",
    "    is_train = tf.placeholder(tf.bool, name='is_train')\n",
    "\n",
    "    global_step = tf.Variable(0, trainable=False)\n",
    "\n",
    "    l_r = tf.train.exponential_decay(\n",
    "        start_lr, global_step, iterations, decay_rate, staircase=True)\n",
    "    tf.summary.scalar('learning_rate', l_r)\n",
    "\n",
    "    opt = tf.train.AdamOptimizer(learning_rate=l_r)\n",
    "\n",
    "    pred = wide_resnet(inputs, k, is_train)\n",
    "    \n",
    "#     l2_loss = tf.losses.get_regularization_loss()\n",
    "    loss = tf.losses.softmax_cross_entropy(outputs, pred)\n",
    "    \n",
    "    grads = opt.compute_gradients(loss)\n",
    "\n",
    "    correct_pred = tf.equal(tf.argmax(pred, 1), tf.argmax(outputs, 1))\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))\n",
    "\n",
    "    update_ops = tf.get_collection(tf.GraphKeys.UPDATE_OPS)\n",
    "\n",
    "    with tf.control_dependencies(update_ops):\n",
    "        train_op = opt.apply_gradients(grads, global_step=global_step)\n",
    "\n",
    "    restore_vars = []\n",
    "\n",
    "    for var in tf.global_variables()[1:51+18]:\n",
    "        if '_coef:0' not in var.name:\n",
    "            restore_vars.append(var)\n",
    "    saver = tf.train.Saver(restore_vars)\n",
    "    \n",
    "    new_saver = tf.train.Saver(tf.global_variables(), max_to_keep=5)\n",
    "\n",
    "    def add_hist(train_vars):\n",
    "        for i in train_vars:\n",
    "            name = i.name.split(\":\")[0] + '/value'\n",
    "            value = i.value()\n",
    "            tf.summary.histogram(name, value)\n",
    "\n",
    "    add_hist(tf.trainable_variables())\n",
    "    tf.summary.scalar('loss', loss)\n",
    "    tf.summary.scalar('accuracy', accuracy)\n",
    "    merged = tf.summary.merge_all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*****************2nd training stage*****************\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/python/training/saver.py:1266: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use standard file APIs to check for files with this prefix.\n",
      "INFO:tensorflow:Restoring parameters from ./wide_resnet_poly_10/cifar10.ckpt-211500\n",
      "Epoch: 1 Train_loss: 4.444 Val_acc: 0.102 Time consumed: 67.5990 s\n",
      "Epoch: 2 Train_loss: 2.933 Val_acc: 0.191 Time consumed: 63.1254 s\n",
      "Epoch: 3 Train_loss: 5.024 Val_acc: 0.216 Time consumed: 62.4010 s\n",
      "Epoch: 4 Train_loss: 2.110 Val_acc: 0.228 Time consumed: 62.4012 s\n",
      "Epoch: 5 Train_loss: 2.049 Val_acc: 0.247 Time consumed: 62.4624 s\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/python/training/saver.py:966: remove_checkpoint (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use standard file APIs to delete files with this prefix.\n",
      "Epoch: 6 Train_loss: 2.330 Val_acc: 0.265 Time consumed: 62.6650 s\n",
      "Epoch: 7 Train_loss: 3.421 Val_acc: 0.281 Time consumed: 62.5216 s\n",
      "Epoch: 8 Train_loss: 2.825 Val_acc: 0.295 Time consumed: 62.6330 s\n",
      "Epoch: 9 Train_loss: 2.330 Val_acc: 0.319 Time consumed: 62.6177 s\n",
      "Epoch: 10 Train_loss: 2.093 Val_acc: 0.328 Time consumed: 62.6282 s\n",
      "Epoch: 11 Train_loss: 2.222 Val_acc: 0.338 Time consumed: 62.5295 s\n",
      "Epoch: 12 Train_loss: 2.045 Val_acc: 0.352 Time consumed: 63.0480 s\n",
      "Epoch: 13 Train_loss: 1.714 Val_acc: 0.364 Time consumed: 62.7738 s\n",
      "Epoch: 14 Train_loss: 1.754 Val_acc: 0.371 Time consumed: 62.7038 s\n",
      "Epoch: 15 Train_loss: 1.609 Val_acc: 0.380 Time consumed: 62.6821 s\n",
      "Epoch: 16 Train_loss: 1.804 Val_acc: 0.387 Time consumed: 62.4542 s\n",
      "Epoch: 17 Train_loss: 2.178 Val_acc: 0.396 Time consumed: 62.0345 s\n",
      "Epoch: 18 Train_loss: 2.455 Val_acc: 0.406 Time consumed: 62.4981 s\n",
      "Epoch: 19 Train_loss: 2.339 Val_acc: 0.413 Time consumed: 62.0875 s\n",
      "Epoch: 20 Train_loss: 1.842 Val_acc: 0.416 Time consumed: 62.3776 s\n",
      "Epoch: 21 Train_loss: 1.590 Val_acc: 0.423 Time consumed: 62.4996 s\n",
      "Epoch: 22 Train_loss: 1.604 Val_acc: 0.428 Time consumed: 62.6161 s\n",
      "Epoch: 23 Train_loss: 1.708 Val_acc: 0.435 Time consumed: 62.6801 s\n",
      "Epoch: 24 Train_loss: 1.787 Val_acc: 0.434 Time consumed: 62.4332 s\n",
      "Epoch: 25 Train_loss: 1.339 Val_acc: 0.439 Time consumed: 63.1876 s\n",
      "Epoch: 26 Train_loss: 1.356 Val_acc: 0.440 Time consumed: 62.5658 s\n",
      "Epoch: 27 Train_loss: 1.554 Val_acc: 0.443 Time consumed: 62.7643 s\n",
      "Epoch: 28 Train_loss: 1.372 Val_acc: 0.440 Time consumed: 62.6198 s\n",
      "Epoch: 29 Train_loss: 1.532 Val_acc: 0.451 Time consumed: 63.1386 s\n",
      "Epoch: 30 Train_loss: 0.866 Val_acc: 0.450 Time consumed: 62.5919 s\n",
      "Epoch: 31 Train_loss: 1.003 Val_acc: 0.454 Time consumed: 62.5938 s\n",
      "Epoch: 32 Train_loss: 1.217 Val_acc: 0.461 Time consumed: 62.0681 s\n"
     ]
    }
   ],
   "source": [
    "config = tf.ConfigProto(allow_soft_placement=True,\n",
    "                        log_device_placement=True)\n",
    "config.gpu_options.allow_growth = True\n",
    "\n",
    "sess = tf.Session(config=config)\n",
    "\n",
    "print('*****************2nd training stage*****************')\n",
    "sess.run(tf.global_variables_initializer())\n",
    "saver.restore(sess, './wide_resnet_poly_10/'+'cifar10.ckpt-211500')\n",
    "train_writer = tf.summary.FileWriter(save_dir+'train', sess.graph)\n",
    "\n",
    "for m in range(epochs):\n",
    "        start = time.time()\n",
    "        batch_gen = datagen.flow(\n",
    "            x_train, y_train, batch_size=batch_size)\n",
    "\n",
    "        for i in range(iterations):\n",
    "            x_batch, y_batch = next(batch_gen)\n",
    "            _, loss_train = sess.run([train_op, loss], \n",
    "                                     {inputs: x_batch, outputs: y_batch, is_train: True})\n",
    "        \n",
    "        summary = sess.run(merged, {inputs: x_batch, outputs: y_batch, is_train: False})\n",
    "        train_writer.add_summary(summary, m*iterations + i + 1)\n",
    "\n",
    "        val_accs = []\n",
    "        for i in range(5000//(batch_size*5)):\n",
    "            val_acc = sess.run(accuracy, {inputs: x_test[i*batch_size*5: (i+1)*batch_size*5],\n",
    "                                          outputs: y_test[i*batch_size*5: (i+1)*batch_size*5],\n",
    "                                          is_train: False})\n",
    "            val_accs.append(val_acc)\n",
    "\n",
    "        if np.mean(val_accs) > old_acc:\n",
    "            old_acc = np.mean(val_accs)\n",
    "            new_saver.save(sess, save_dir+'cifar10.ckpt', global_step=global_step)\n",
    "\n",
    "        end = time.time()\n",
    "        print('Epoch: {}'.format(m + 1),\n",
    "              'Train_loss: {:.3f}'.format(loss_train),\n",
    "              'Val_acc: {:.3f}'.format(np.mean(val_accs)),\n",
    "              'Time consumed: {:.4f} s'.format(end - start))\n",
    "\n",
    "print('*****************Training End!*****************')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
