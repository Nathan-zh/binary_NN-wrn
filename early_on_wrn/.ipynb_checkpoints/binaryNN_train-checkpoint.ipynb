{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -rf ./binary_resnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%config IPCompleter.greedy=True\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 32, 32, 3)\n",
      "(50000, 10)\n",
      "(10000, 32, 32, 3)\n",
      "(10000, 10)\n"
     ]
    }
   ],
   "source": [
    "%run ./datagen.py\n",
    "#datagen, (x_train, y_train), (x_test, y_test) = data_preparation()\n",
    "\n",
    "datagen, (x_train, y_train), (x_test, y_test) = data_preparation()\n",
    "print(x_train.shape)\n",
    "print(y_train.shape)\n",
    "print(x_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_logdir = './binary_resnet/'\n",
    "path_model = './binary_resnet/'\n",
    "num_gpu = 5\n",
    "batch_size = 100\n",
    "iterations = x_train.shape[0] // (batch_size * num_gpu)\n",
    "epochs = 800\n",
    "old_acc = 0\n",
    "start_lr = 1e-2\n",
    "end_lr = 1e-4\n",
    "decay_rate = (end_lr / start_lr) ** (1 / epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %run ./binary_layer.py \n",
    "# # binary_dense: dense()\n",
    "# # binary_conv2d: conv2d()\n",
    "\n",
    "# def inference(inputs, is_train):\n",
    "\n",
    "#     # L1: 2*128conv + pooling + bn\n",
    "#     with tf.variable_scope(\"ConvBlock1\"):\n",
    "#         x = conv2d(inputs=inputs, \n",
    "#                    filters=128, \n",
    "#                    kernel_size=(3, 3),\n",
    "#                    strides=(1, 1), \n",
    "#                    padding='same')\n",
    "#         x = tf.layers.batch_normalization(x, training=is_train)\n",
    "#         x = tf.nn.sigmoid(x)\n",
    "\n",
    "#         x = conv2d(inputs=x,\n",
    "#                    filters=128, \n",
    "#                    kernel_size=(3, 3), \n",
    "#                    strides=(1, 1), \n",
    "#                    padding='same')\n",
    "#         x = 4 * tf.layers.average_pooling2d(x, pool_size=(2, 2), strides=(2, 2), padding='SAME')\n",
    "#         x = tf.layers.batch_normalization(x, training=is_train)        \n",
    "#         x = tf.nn.sigmoid(x)\n",
    "# #         x = tf.layers.dropout(x, 0.1)\n",
    "\n",
    "#     # L2: 2*256conv + pooling + bn + dropout\n",
    "#     with tf.variable_scope(\"ConvBlock2\"):\n",
    "#         x = conv2d(inputs=x,\n",
    "#                    filters=256, \n",
    "#                    kernel_size=(3, 3), \n",
    "#                    strides=(1, 1), \n",
    "#                    padding='same')\n",
    "#         x = tf.layers.batch_normalization(x, training=is_train)        \n",
    "#         x = tf.nn.sigmoid(x)\n",
    "\n",
    "#         x = conv2d(inputs=x,\n",
    "#                    filters=256, \n",
    "#                    kernel_size=(3, 3), \n",
    "#                    strides=(1, 1), \n",
    "#                    padding='same')\n",
    "#         x = 4*tf.layers.average_pooling2d(x, pool_size=(2, 2), strides=(2, 2), padding='SAME')\n",
    "#         x = tf.layers.batch_normalization(x, training=is_train)\n",
    "#         x = tf.nn.sigmoid(x)\n",
    "# #         x = tf.layers.dropout(x, 0.1)\n",
    "\n",
    "#     # L3: 2*512conv + pooling + dropout\n",
    "#     with tf.variable_scope(\"ConvBlock3\"):\n",
    "#         x = conv2d(inputs=x,\n",
    "#                    filters=512, \n",
    "#                    kernel_size=(3, 3), \n",
    "#                    strides=(1, 1), \n",
    "#                    padding='same')\n",
    "#         x = tf.layers.batch_normalization(x, training=is_train)\n",
    "#         x = tf.nn.sigmoid(x)\n",
    "        \n",
    "#         x = conv2d(inputs=x,\n",
    "#                    filters=512, \n",
    "#                    kernel_size=(3, 3), \n",
    "#                    strides=(1, 1), \n",
    "#                    padding='same')\n",
    "#         x = 4*tf.layers.average_pooling2d(x, pool_size=(2, 2), strides=(2, 2), padding='SAME')\n",
    "#         x = tf.layers.batch_normalization(x, training=is_train)\n",
    "#         x = tf.nn.sigmoid(x)    \n",
    "# #         x = tf.layers.dropout(x, 0.1)\n",
    "\n",
    "#     with tf.variable_scope(\"Flatten\"):\n",
    "#         x = tf.transpose(x, perm=[0, 3, 1, 2])\n",
    "#         x = tf.layers.flatten(x)\n",
    "\n",
    "#     # L4: 2*FC1024 + bn + dropout\n",
    "#     with tf.variable_scope(\"FCBlock1\"):\n",
    "#         x = dense(x, units=1024)\n",
    "#         x = tf.layers.batch_normalization(x, training=is_train)       \n",
    "#         x = tf.nn.sigmoid(x)\n",
    "\n",
    "#         x = dense(x, units=1024)\n",
    "#         x = tf.layers.batch_normalization(x, training=is_train)\n",
    "#         x = tf.nn.sigmoid(x)   \n",
    "# #         x = tf.layers.dropout(x, 0.1)\n",
    "\n",
    "#     # predict layer\n",
    "#     with tf.variable_scope(\"Prediction\"):\n",
    "#         pred = dense(x, units=10)\n",
    "    \n",
    "#     return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run ./binary_layer.py \n",
    "\n",
    "# resnet layer\n",
    "def res_layer(inputs, filter_num, filter_size, stride, is_train, \n",
    "              conv_first=False, batch_norm=True, activation=True):\n",
    "    \n",
    "    x = inputs\n",
    "    \n",
    "    if conv_first:\n",
    "        x = conv2d(inputs=x, filters=filter_num, \n",
    "                   kernel_size=filter_size, strides=stride, padding='same')\n",
    "        if batch_norm:\n",
    "            x = tf.layers.batch_normalization(x, training=is_train)\n",
    "        if activation:\n",
    "            x = tf.nn.sigmoid(x)\n",
    "    else:\n",
    "        if batch_norm:\n",
    "            x = tf.layers.batch_normalization(x, training=is_train)\n",
    "        if activation:\n",
    "            x = tf.nn.sigmoid(x)\n",
    "        x = conv2d(inputs=x, filters=filter_num, \n",
    "                   kernel_size=filter_size, strides=stride, padding='same')\n",
    "    \n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resnetv2(inputs, is_train):\n",
    "    \n",
    "    with tf.variable_scope(\"Conv1\"):\n",
    "        x = res_layer(inputs, 64, 3, 2, is_train, conv_first=True)\n",
    "          \n",
    "    # Res Blocks\n",
    "    for stack in range(3):\n",
    "        for block in range(6):\n",
    "            with tf.variable_scope('ResBlock{}'.format(stack*6+block+1)):\n",
    "                \n",
    "                batch_norm = True\n",
    "                activation = True\n",
    "                stride = 1\n",
    "                if stack == 0:\n",
    "                    filter_num = 64\n",
    "                    if block == 0:\n",
    "                        batch_norm = False\n",
    "                        activation = False\n",
    "                else:\n",
    "                    filter_num = 64*2*stack\n",
    "                    if block == 0:\n",
    "                        stride = 2\n",
    "                \n",
    "                residual_x = x\n",
    "                with tf.variable_scope('conv1'):\n",
    "                    x = res_layer(x, filter_num, 1, stride, is_train, \n",
    "                                  batch_norm=batch_norm, activation=activation)\n",
    "                with tf.variable_scope('conv2'):\n",
    "                    x = res_layer(x, filter_num, 3, 1, is_train, \n",
    "                                  batch_norm=batch_norm, activation=activation)\n",
    "                with tf.variable_scope('conv3'):\n",
    "                    x = res_layer(x, filter_num*4, 1, 1, is_train, \n",
    "                                  batch_norm=batch_norm, activation=activation)\n",
    "                if block == 0:\n",
    "                    with tf.variable_scope('residual'):\n",
    "                        residual_x = res_layer(residual_x, filter_num*4, 1, stride, is_train, \n",
    "                                               batch_norm=False, activation=False)\n",
    "                x = x + residual_x   \n",
    "    \n",
    "    #x.shape = (?, 4, 4, 1024)\n",
    "    with tf.variable_scope(\"AfterResBlock\"):\n",
    "        x = tf.layers.batch_normalization(x, training=is_train)                \n",
    "        x = tf.nn.sigmoid(x)\n",
    "        x = 4 * tf.layers.average_pooling2d(x, pool_size=2, strides=2, padding='SAME', name='pool1')\n",
    "    \n",
    "    with tf.variable_scope(\"Flatten\"):\n",
    "        x = tf.transpose(x, perm=[0, 3, 1, 2])\n",
    "        x = tf.layers.flatten(x)\n",
    "    \n",
    "    with tf.variable_scope(\"Prediction\"):\n",
    "        pred = tf.layers.dense(x, units=10)\n",
    "        \n",
    "    return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def average_gradients(tower_grads):\n",
    "    average_grads = []\n",
    "    for grad_and_vars in zip(*tower_grads):\n",
    "        grads = []\n",
    "        for g, _ in grad_and_vars:\n",
    "            expend_g = tf.expand_dims(g, 0)\n",
    "            grads.append(expend_g)\n",
    "        grad = tf.concat(grads, 0)\n",
    "        grad = tf.reduce_mean(grad, 0)\n",
    "        v = grad_and_vars[0][1]\n",
    "        grad_and_var = (grad, v)\n",
    "        average_grads.append(grad_and_var)\n",
    "    return average_grads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From <ipython-input-6-ccc1d334de9b>:13: batch_normalization (from tensorflow.python.layers.normalization) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.batch_normalization instead.\n",
      "WARNING:tensorflow:From <ipython-input-7-a1113ce24a05>:44: average_pooling2d (from tensorflow.python.layers.pooling) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.average_pooling2d instead.\n",
      "WARNING:tensorflow:From <ipython-input-7-a1113ce24a05>:48: flatten (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.flatten instead.\n",
      "WARNING:tensorflow:From <ipython-input-7-a1113ce24a05>:51: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.dense instead.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/losses/losses_impl.py:209: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n"
     ]
    }
   ],
   "source": [
    "with tf.device(\"/cpu:0\"):\n",
    "    \n",
    "    inputs = tf.placeholder(tf.float32, [None, 32, 32, 3], name='input')\n",
    "    outputs = tf.placeholder(tf.float32, [None, 10], name='output')\n",
    "    is_train = tf.placeholder(tf.bool, name='is_train')\n",
    "    \n",
    "    global_step = tf.Variable(0, trainable=False)\n",
    "    l_r = tf.train.exponential_decay(start_lr, global_step, iterations, decay_rate, staircase=True)\n",
    "    update_ops = tf.get_collection(tf.GraphKeys.UPDATE_OPS)\n",
    "    with tf.control_dependencies(update_ops):\n",
    "        opt = tf.train.AdamOptimizer(learning_rate=l_r)\n",
    "\n",
    "    tower_grads = []\n",
    "    tower_acc = []\n",
    "    tower_loss = []\n",
    "    \n",
    "    with tf.variable_scope(tf.get_variable_scope()) as variable_scope:\n",
    "#         print('-'*20)\n",
    "#         print(variable_scope.name)\n",
    "#         print('-'*20)\n",
    "        for i in range(num_gpu):\n",
    "            with tf.device('/gpu:%d' % i):\n",
    "                with tf.name_scope('%s_%d' % ('tower', i)) as scope:\n",
    "                    x = inputs[i * batch_size:(i + 1) * batch_size]\n",
    "                    y = outputs[i * batch_size:(i + 1) * batch_size]\n",
    "                    pred = resnetv2(x, is_train)\n",
    "                    \n",
    "                    tf.get_variable_scope().reuse_variables()\n",
    "                    \n",
    "                    loss = tf.losses.softmax_cross_entropy(y, pred)\n",
    "                    tower_loss.append(loss)\n",
    "#                     loss = tf.reduce_mean(tf.nn.sigmoid(tf.losses.hinge_loss(y, pred)))\n",
    "                    grads = opt.compute_gradients(loss)\n",
    "                    tower_grads.append(grads)\n",
    "\n",
    "                    correct_pred = tf.equal(tf.argmax(pred, 1), tf.argmax(y, 1))\n",
    "                    accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))\n",
    "                    tower_acc.append(accuracy)\n",
    "    \n",
    "    losses = tf.reduce_mean(tower_loss)\n",
    "    grads = average_gradients(tower_grads)\n",
    "    accs = tf.reduce_mean(tower_acc)\n",
    "    update_ops = tf.get_collection(tf.GraphKeys.UPDATE_OPS)\n",
    "    with tf.control_dependencies(update_ops):\n",
    "        train_op = opt.apply_gradients(grads, global_step=global_step)\n",
    "    \n",
    "    saver = tf.train.Saver(tf.global_variables())\n",
    "    tf.summary.scalar('loss', losses)\n",
    "    tf.summary.scalar('accuracy', accs)\n",
    "    tf.summary.scalar('learning_rate', l_r)\n",
    "    merged = tf.summary.merge_all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*****************Training Start!*****************\n",
      "Epoch: 1 Train_loss: 12.856 Val_acc: 0.146 Time consumed: 94.5805 s\n",
      "Epoch: 2 Train_loss: 9.810 Val_acc: 0.185 Time consumed: 50.5846 s\n",
      "Epoch: 3 Train_loss: 16.951 Val_acc: 0.160 Time consumed: 46.0162 s\n",
      "Epoch: 4 Train_loss: 4.246 Val_acc: 0.168 Time consumed: 46.3472 s\n",
      "Epoch: 5 Train_loss: 9.225 Val_acc: 0.123 Time consumed: 45.9266 s\n",
      "Epoch: 6 Train_loss: 3.588 Val_acc: 0.196 Time consumed: 49.6013 s\n",
      "Epoch: 7 Train_loss: 2.232 Val_acc: 0.233 Time consumed: 49.5704 s\n",
      "Epoch: 8 Train_loss: 5.341 Val_acc: 0.138 Time consumed: 46.3116 s\n",
      "Epoch: 9 Train_loss: 2.494 Val_acc: 0.203 Time consumed: 45.9447 s\n",
      "Epoch: 10 Train_loss: 1.867 Val_acc: 0.247 Time consumed: 49.1349 s\n",
      "Epoch: 11 Train_loss: 1.908 Val_acc: 0.228 Time consumed: 46.2065 s\n",
      "Epoch: 12 Train_loss: 3.613 Val_acc: 0.213 Time consumed: 46.1352 s\n",
      "Epoch: 13 Train_loss: 1.933 Val_acc: 0.180 Time consumed: 46.0883 s\n",
      "Epoch: 14 Train_loss: 2.484 Val_acc: 0.251 Time consumed: 49.5479 s\n",
      "Epoch: 15 Train_loss: 1.993 Val_acc: 0.295 Time consumed: 49.8241 s\n",
      "Epoch: 16 Train_loss: 1.986 Val_acc: 0.339 Time consumed: 49.9534 s\n",
      "Epoch: 17 Train_loss: 1.748 Val_acc: 0.208 Time consumed: 45.8832 s\n",
      "Epoch: 18 Train_loss: 1.877 Val_acc: 0.282 Time consumed: 45.6949 s\n",
      "Epoch: 19 Train_loss: 1.877 Val_acc: 0.347 Time consumed: 49.5551 s\n",
      "Epoch: 20 Train_loss: 2.000 Val_acc: 0.352 Time consumed: 49.5311 s\n",
      "Epoch: 21 Train_loss: 1.958 Val_acc: 0.263 Time consumed: 46.1040 s\n",
      "Epoch: 22 Train_loss: 1.895 Val_acc: 0.335 Time consumed: 46.0188 s\n",
      "Epoch: 23 Train_loss: 1.807 Val_acc: 0.331 Time consumed: 45.8141 s\n",
      "Epoch: 24 Train_loss: 1.691 Val_acc: 0.328 Time consumed: 46.0212 s\n",
      "Epoch: 25 Train_loss: 1.920 Val_acc: 0.323 Time consumed: 45.9165 s\n",
      "Epoch: 26 Train_loss: 1.818 Val_acc: 0.320 Time consumed: 46.0823 s\n",
      "Epoch: 27 Train_loss: 1.812 Val_acc: 0.362 Time consumed: 49.3537 s\n",
      "Epoch: 28 Train_loss: 1.715 Val_acc: 0.331 Time consumed: 45.6821 s\n",
      "Epoch: 29 Train_loss: 1.829 Val_acc: 0.353 Time consumed: 46.0545 s\n",
      "Epoch: 30 Train_loss: 1.610 Val_acc: 0.309 Time consumed: 45.7250 s\n",
      "Epoch: 31 Train_loss: 1.731 Val_acc: 0.260 Time consumed: 45.6685 s\n",
      "Epoch: 32 Train_loss: 1.930 Val_acc: 0.151 Time consumed: 45.9736 s\n",
      "Epoch: 33 Train_loss: 1.568 Val_acc: 0.238 Time consumed: 46.1111 s\n",
      "Epoch: 34 Train_loss: 1.572 Val_acc: 0.272 Time consumed: 46.3284 s\n",
      "Epoch: 35 Train_loss: 1.758 Val_acc: 0.257 Time consumed: 46.4043 s\n",
      "Epoch: 36 Train_loss: 1.602 Val_acc: 0.304 Time consumed: 46.2360 s\n",
      "Epoch: 37 Train_loss: 1.556 Val_acc: 0.446 Time consumed: 50.1400 s\n",
      "Epoch: 38 Train_loss: 1.587 Val_acc: 0.372 Time consumed: 46.5339 s\n",
      "Epoch: 39 Train_loss: 1.563 Val_acc: 0.339 Time consumed: 46.1647 s\n",
      "Epoch: 40 Train_loss: 1.580 Val_acc: 0.359 Time consumed: 46.4060 s\n",
      "Epoch: 41 Train_loss: 1.459 Val_acc: 0.396 Time consumed: 46.2186 s\n",
      "Epoch: 42 Train_loss: 1.578 Val_acc: 0.379 Time consumed: 46.1165 s\n",
      "Epoch: 43 Train_loss: 1.616 Val_acc: 0.381 Time consumed: 46.7746 s\n",
      "Epoch: 44 Train_loss: 1.451 Val_acc: 0.352 Time consumed: 46.5106 s\n",
      "Epoch: 45 Train_loss: 1.485 Val_acc: 0.355 Time consumed: 45.9931 s\n",
      "Epoch: 46 Train_loss: 1.363 Val_acc: 0.434 Time consumed: 46.5912 s\n",
      "Epoch: 47 Train_loss: 1.507 Val_acc: 0.443 Time consumed: 46.2485 s\n",
      "Epoch: 48 Train_loss: 1.437 Val_acc: 0.349 Time consumed: 46.9600 s\n",
      "Epoch: 49 Train_loss: 1.441 Val_acc: 0.403 Time consumed: 46.6473 s\n",
      "Epoch: 50 Train_loss: 1.510 Val_acc: 0.315 Time consumed: 46.8346 s\n",
      "Epoch: 51 Train_loss: 1.380 Val_acc: 0.221 Time consumed: 46.7004 s\n",
      "Epoch: 52 Train_loss: 1.334 Val_acc: 0.340 Time consumed: 46.7497 s\n",
      "Epoch: 53 Train_loss: 1.352 Val_acc: 0.354 Time consumed: 46.5995 s\n",
      "Epoch: 54 Train_loss: 1.349 Val_acc: 0.368 Time consumed: 46.3971 s\n",
      "Epoch: 55 Train_loss: 1.413 Val_acc: 0.391 Time consumed: 46.3542 s\n",
      "Epoch: 56 Train_loss: 1.399 Val_acc: 0.369 Time consumed: 46.6522 s\n",
      "Epoch: 57 Train_loss: 1.370 Val_acc: 0.386 Time consumed: 46.8617 s\n",
      "Epoch: 58 Train_loss: 1.404 Val_acc: 0.411 Time consumed: 46.4763 s\n",
      "Epoch: 59 Train_loss: 1.313 Val_acc: 0.370 Time consumed: 47.4457 s\n",
      "Epoch: 60 Train_loss: 1.281 Val_acc: 0.450 Time consumed: 50.9760 s\n",
      "Epoch: 61 Train_loss: 1.322 Val_acc: 0.341 Time consumed: 46.2323 s\n",
      "Epoch: 62 Train_loss: 1.388 Val_acc: 0.351 Time consumed: 47.3460 s\n",
      "Epoch: 63 Train_loss: 1.428 Val_acc: 0.479 Time consumed: 49.8736 s\n",
      "Epoch: 64 Train_loss: 1.245 Val_acc: 0.362 Time consumed: 46.5373 s\n",
      "Epoch: 65 Train_loss: 1.311 Val_acc: 0.447 Time consumed: 46.7049 s\n",
      "Epoch: 66 Train_loss: 1.393 Val_acc: 0.437 Time consumed: 46.1432 s\n",
      "Epoch: 67 Train_loss: 1.309 Val_acc: 0.355 Time consumed: 46.3687 s\n",
      "Epoch: 68 Train_loss: 1.249 Val_acc: 0.342 Time consumed: 46.6686 s\n",
      "Epoch: 69 Train_loss: 1.291 Val_acc: 0.358 Time consumed: 46.2489 s\n",
      "Epoch: 70 Train_loss: 1.346 Val_acc: 0.477 Time consumed: 45.8097 s\n",
      "Epoch: 71 Train_loss: 1.282 Val_acc: 0.342 Time consumed: 46.4124 s\n",
      "Epoch: 72 Train_loss: 1.330 Val_acc: 0.528 Time consumed: 49.5656 s\n",
      "Epoch: 73 Train_loss: 1.321 Val_acc: 0.478 Time consumed: 46.8209 s\n",
      "Epoch: 74 Train_loss: 1.213 Val_acc: 0.463 Time consumed: 46.2691 s\n",
      "Epoch: 75 Train_loss: 1.322 Val_acc: 0.312 Time consumed: 46.4385 s\n",
      "Epoch: 76 Train_loss: 1.301 Val_acc: 0.310 Time consumed: 46.7983 s\n",
      "Epoch: 77 Train_loss: 1.292 Val_acc: 0.428 Time consumed: 46.7766 s\n",
      "Epoch: 78 Train_loss: 1.317 Val_acc: 0.464 Time consumed: 45.9841 s\n",
      "Epoch: 79 Train_loss: 1.225 Val_acc: 0.495 Time consumed: 46.3204 s\n",
      "Epoch: 80 Train_loss: 1.274 Val_acc: 0.487 Time consumed: 47.4892 s\n",
      "Epoch: 81 Train_loss: 1.278 Val_acc: 0.489 Time consumed: 47.4034 s\n",
      "Epoch: 82 Train_loss: 1.208 Val_acc: 0.312 Time consumed: 46.9105 s\n",
      "Epoch: 83 Train_loss: 1.215 Val_acc: 0.328 Time consumed: 46.2194 s\n",
      "Epoch: 84 Train_loss: 1.131 Val_acc: 0.500 Time consumed: 45.9739 s\n",
      "Epoch: 85 Train_loss: 1.241 Val_acc: 0.511 Time consumed: 46.6861 s\n",
      "Epoch: 86 Train_loss: 1.221 Val_acc: 0.516 Time consumed: 47.1340 s\n",
      "Epoch: 87 Train_loss: 1.128 Val_acc: 0.396 Time consumed: 47.3328 s\n",
      "Epoch: 88 Train_loss: 1.218 Val_acc: 0.441 Time consumed: 47.7169 s\n",
      "Epoch: 89 Train_loss: 1.211 Val_acc: 0.414 Time consumed: 46.5876 s\n",
      "Epoch: 90 Train_loss: 1.271 Val_acc: 0.398 Time consumed: 46.9356 s\n",
      "Epoch: 91 Train_loss: 1.173 Val_acc: 0.505 Time consumed: 46.4660 s\n",
      "Epoch: 92 Train_loss: 1.316 Val_acc: 0.515 Time consumed: 46.0702 s\n",
      "Epoch: 93 Train_loss: 1.303 Val_acc: 0.446 Time consumed: 46.4357 s\n",
      "Epoch: 94 Train_loss: 1.205 Val_acc: 0.346 Time consumed: 46.1860 s\n",
      "Epoch: 95 Train_loss: 1.220 Val_acc: 0.518 Time consumed: 46.5858 s\n",
      "Epoch: 96 Train_loss: 1.187 Val_acc: 0.501 Time consumed: 46.0348 s\n",
      "Epoch: 97 Train_loss: 1.313 Val_acc: 0.502 Time consumed: 46.2353 s\n",
      "Epoch: 98 Train_loss: 1.163 Val_acc: 0.399 Time consumed: 46.3527 s\n",
      "Epoch: 99 Train_loss: 1.138 Val_acc: 0.472 Time consumed: 46.6113 s\n",
      "Epoch: 100 Train_loss: 1.305 Val_acc: 0.406 Time consumed: 46.2607 s\n",
      "Epoch: 101 Train_loss: 1.243 Val_acc: 0.498 Time consumed: 47.0820 s\n",
      "Epoch: 102 Train_loss: 1.249 Val_acc: 0.551 Time consumed: 51.5891 s\n",
      "Epoch: 103 Train_loss: 1.118 Val_acc: 0.399 Time consumed: 45.8623 s\n",
      "Epoch: 104 Train_loss: 1.216 Val_acc: 0.505 Time consumed: 46.0834 s\n",
      "Epoch: 105 Train_loss: 1.160 Val_acc: 0.342 Time consumed: 45.8007 s\n",
      "Epoch: 106 Train_loss: 1.230 Val_acc: 0.465 Time consumed: 46.0251 s\n",
      "Epoch: 107 Train_loss: 1.047 Val_acc: 0.427 Time consumed: 46.1284 s\n",
      "Epoch: 108 Train_loss: 1.134 Val_acc: 0.477 Time consumed: 46.4673 s\n",
      "Epoch: 109 Train_loss: 1.145 Val_acc: 0.525 Time consumed: 46.9052 s\n",
      "Epoch: 110 Train_loss: 1.110 Val_acc: 0.485 Time consumed: 47.4211 s\n",
      "Epoch: 111 Train_loss: 1.142 Val_acc: 0.487 Time consumed: 47.3638 s\n",
      "Epoch: 112 Train_loss: 1.146 Val_acc: 0.413 Time consumed: 47.8598 s\n",
      "Epoch: 113 Train_loss: 1.239 Val_acc: 0.432 Time consumed: 47.6509 s\n",
      "Epoch: 114 Train_loss: 1.036 Val_acc: 0.537 Time consumed: 47.3470 s\n",
      "Epoch: 115 Train_loss: 1.142 Val_acc: 0.449 Time consumed: 46.4438 s\n",
      "Epoch: 116 Train_loss: 1.182 Val_acc: 0.389 Time consumed: 46.2599 s\n",
      "Epoch: 117 Train_loss: 1.147 Val_acc: 0.441 Time consumed: 46.0670 s\n",
      "Epoch: 118 Train_loss: 1.093 Val_acc: 0.459 Time consumed: 46.3431 s\n",
      "Epoch: 119 Train_loss: 1.100 Val_acc: 0.503 Time consumed: 46.4979 s\n",
      "Epoch: 120 Train_loss: 1.266 Val_acc: 0.531 Time consumed: 45.9244 s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 121 Train_loss: 1.093 Val_acc: 0.382 Time consumed: 46.7115 s\n",
      "Epoch: 122 Train_loss: 1.158 Val_acc: 0.404 Time consumed: 46.1545 s\n",
      "Epoch: 123 Train_loss: 1.161 Val_acc: 0.518 Time consumed: 45.9088 s\n",
      "Epoch: 124 Train_loss: 1.182 Val_acc: 0.534 Time consumed: 45.9551 s\n",
      "Epoch: 125 Train_loss: 1.064 Val_acc: 0.404 Time consumed: 46.2969 s\n",
      "Epoch: 126 Train_loss: 1.062 Val_acc: 0.477 Time consumed: 46.5050 s\n",
      "Epoch: 127 Train_loss: 1.142 Val_acc: 0.418 Time consumed: 46.5288 s\n",
      "Epoch: 128 Train_loss: 1.142 Val_acc: 0.415 Time consumed: 46.3545 s\n",
      "Epoch: 129 Train_loss: 1.083 Val_acc: 0.359 Time consumed: 45.9711 s\n",
      "Epoch: 130 Train_loss: 1.133 Val_acc: 0.558 Time consumed: 50.7737 s\n",
      "Epoch: 131 Train_loss: 1.222 Val_acc: 0.507 Time consumed: 45.9198 s\n",
      "Epoch: 132 Train_loss: 1.121 Val_acc: 0.320 Time consumed: 45.9711 s\n",
      "Epoch: 133 Train_loss: 1.164 Val_acc: 0.421 Time consumed: 46.0179 s\n",
      "Epoch: 134 Train_loss: 1.069 Val_acc: 0.497 Time consumed: 45.9147 s\n",
      "Epoch: 135 Train_loss: 1.146 Val_acc: 0.440 Time consumed: 45.8004 s\n",
      "Epoch: 136 Train_loss: 1.078 Val_acc: 0.549 Time consumed: 45.7142 s\n",
      "Epoch: 137 Train_loss: 1.030 Val_acc: 0.504 Time consumed: 45.7689 s\n",
      "Epoch: 138 Train_loss: 1.218 Val_acc: 0.233 Time consumed: 46.1954 s\n",
      "Epoch: 139 Train_loss: 1.063 Val_acc: 0.487 Time consumed: 45.8084 s\n",
      "Epoch: 140 Train_loss: 1.108 Val_acc: 0.281 Time consumed: 45.6293 s\n",
      "Epoch: 141 Train_loss: 1.223 Val_acc: 0.471 Time consumed: 45.7760 s\n",
      "Epoch: 142 Train_loss: 1.183 Val_acc: 0.412 Time consumed: 45.8547 s\n",
      "Epoch: 143 Train_loss: 1.114 Val_acc: 0.417 Time consumed: 45.9801 s\n",
      "Epoch: 144 Train_loss: 1.038 Val_acc: 0.493 Time consumed: 45.8688 s\n",
      "Epoch: 145 Train_loss: 1.124 Val_acc: 0.502 Time consumed: 45.9329 s\n",
      "Epoch: 146 Train_loss: 1.080 Val_acc: 0.526 Time consumed: 45.9094 s\n",
      "Epoch: 147 Train_loss: 1.028 Val_acc: 0.498 Time consumed: 45.9318 s\n",
      "Epoch: 148 Train_loss: 1.122 Val_acc: 0.535 Time consumed: 46.1884 s\n",
      "Epoch: 149 Train_loss: 1.186 Val_acc: 0.372 Time consumed: 46.3217 s\n",
      "Epoch: 150 Train_loss: 1.069 Val_acc: 0.193 Time consumed: 46.3492 s\n",
      "Epoch: 151 Train_loss: 1.101 Val_acc: 0.422 Time consumed: 46.7023 s\n",
      "Epoch: 152 Train_loss: 1.155 Val_acc: 0.447 Time consumed: 46.9821 s\n",
      "Epoch: 153 Train_loss: 1.043 Val_acc: 0.399 Time consumed: 46.2698 s\n",
      "Epoch: 154 Train_loss: 1.084 Val_acc: 0.238 Time consumed: 45.7231 s\n",
      "Epoch: 155 Train_loss: 1.115 Val_acc: 0.533 Time consumed: 46.0201 s\n",
      "Epoch: 156 Train_loss: 1.074 Val_acc: 0.437 Time consumed: 45.8404 s\n",
      "Epoch: 157 Train_loss: 1.087 Val_acc: 0.517 Time consumed: 46.1040 s\n",
      "Epoch: 158 Train_loss: 1.058 Val_acc: 0.441 Time consumed: 46.3293 s\n",
      "Epoch: 159 Train_loss: 1.148 Val_acc: 0.465 Time consumed: 46.2465 s\n",
      "Epoch: 160 Train_loss: 1.051 Val_acc: 0.549 Time consumed: 46.7483 s\n",
      "Epoch: 161 Train_loss: 1.116 Val_acc: 0.476 Time consumed: 45.9852 s\n",
      "Epoch: 162 Train_loss: 1.072 Val_acc: 0.414 Time consumed: 46.4022 s\n",
      "Epoch: 163 Train_loss: 1.021 Val_acc: 0.529 Time consumed: 46.5589 s\n",
      "Epoch: 164 Train_loss: 1.029 Val_acc: 0.524 Time consumed: 47.6714 s\n",
      "Epoch: 165 Train_loss: 1.104 Val_acc: 0.398 Time consumed: 45.6209 s\n",
      "Epoch: 166 Train_loss: 1.032 Val_acc: 0.329 Time consumed: 45.6626 s\n",
      "Epoch: 167 Train_loss: 1.107 Val_acc: 0.507 Time consumed: 46.0433 s\n",
      "Epoch: 168 Train_loss: 1.085 Val_acc: 0.412 Time consumed: 45.7001 s\n",
      "Epoch: 169 Train_loss: 1.057 Val_acc: 0.492 Time consumed: 45.7329 s\n",
      "Epoch: 170 Train_loss: 1.109 Val_acc: 0.533 Time consumed: 46.1208 s\n",
      "Epoch: 171 Train_loss: 1.011 Val_acc: 0.535 Time consumed: 45.9706 s\n",
      "Epoch: 172 Train_loss: 0.972 Val_acc: 0.550 Time consumed: 45.7242 s\n",
      "Epoch: 173 Train_loss: 1.134 Val_acc: 0.432 Time consumed: 45.9001 s\n",
      "Epoch: 174 Train_loss: 1.160 Val_acc: 0.509 Time consumed: 45.8643 s\n",
      "Epoch: 175 Train_loss: 1.006 Val_acc: 0.524 Time consumed: 45.6654 s\n",
      "Epoch: 176 Train_loss: 1.067 Val_acc: 0.414 Time consumed: 45.9478 s\n",
      "Epoch: 177 Train_loss: 1.126 Val_acc: 0.518 Time consumed: 45.4783 s\n",
      "Epoch: 178 Train_loss: 0.953 Val_acc: 0.307 Time consumed: 45.8947 s\n",
      "Epoch: 179 Train_loss: 1.048 Val_acc: 0.491 Time consumed: 45.9574 s\n",
      "Epoch: 180 Train_loss: 1.092 Val_acc: 0.535 Time consumed: 46.2623 s\n",
      "Epoch: 181 Train_loss: 1.075 Val_acc: 0.297 Time consumed: 46.0485 s\n",
      "Epoch: 182 Train_loss: 1.069 Val_acc: 0.289 Time consumed: 45.6425 s\n",
      "Epoch: 183 Train_loss: 1.034 Val_acc: 0.573 Time consumed: 50.2588 s\n",
      "Epoch: 184 Train_loss: 1.044 Val_acc: 0.528 Time consumed: 45.9088 s\n",
      "Epoch: 185 Train_loss: 0.997 Val_acc: 0.508 Time consumed: 45.7204 s\n",
      "Epoch: 186 Train_loss: 1.152 Val_acc: 0.452 Time consumed: 45.6744 s\n",
      "Epoch: 187 Train_loss: 1.010 Val_acc: 0.559 Time consumed: 45.9110 s\n",
      "Epoch: 188 Train_loss: 1.048 Val_acc: 0.403 Time consumed: 45.9978 s\n",
      "Epoch: 189 Train_loss: 1.143 Val_acc: 0.418 Time consumed: 46.0668 s\n",
      "Epoch: 190 Train_loss: 1.054 Val_acc: 0.551 Time consumed: 46.0292 s\n",
      "Epoch: 191 Train_loss: 1.015 Val_acc: 0.239 Time consumed: 46.0162 s\n",
      "Epoch: 192 Train_loss: 1.019 Val_acc: 0.571 Time consumed: 46.0243 s\n",
      "Epoch: 193 Train_loss: 1.054 Val_acc: 0.480 Time consumed: 46.1463 s\n",
      "Epoch: 194 Train_loss: 1.080 Val_acc: 0.452 Time consumed: 45.9388 s\n",
      "Epoch: 195 Train_loss: 1.071 Val_acc: 0.336 Time consumed: 45.9702 s\n",
      "Epoch: 196 Train_loss: 1.086 Val_acc: 0.481 Time consumed: 45.7292 s\n",
      "Epoch: 197 Train_loss: 1.092 Val_acc: 0.413 Time consumed: 45.6515 s\n",
      "Epoch: 198 Train_loss: 1.030 Val_acc: 0.579 Time consumed: 50.2004 s\n",
      "Epoch: 199 Train_loss: 1.068 Val_acc: 0.473 Time consumed: 45.3195 s\n",
      "Epoch: 200 Train_loss: 0.989 Val_acc: 0.496 Time consumed: 45.6468 s\n",
      "Epoch: 201 Train_loss: 1.003 Val_acc: 0.483 Time consumed: 45.9544 s\n",
      "Epoch: 202 Train_loss: 1.084 Val_acc: 0.553 Time consumed: 45.6340 s\n",
      "Epoch: 203 Train_loss: 0.969 Val_acc: 0.547 Time consumed: 45.8685 s\n",
      "Epoch: 204 Train_loss: 1.065 Val_acc: 0.385 Time consumed: 45.8919 s\n",
      "Epoch: 205 Train_loss: 1.047 Val_acc: 0.479 Time consumed: 45.9765 s\n",
      "Epoch: 206 Train_loss: 1.040 Val_acc: 0.454 Time consumed: 45.7671 s\n",
      "Epoch: 207 Train_loss: 0.984 Val_acc: 0.561 Time consumed: 45.5673 s\n",
      "Epoch: 208 Train_loss: 1.021 Val_acc: 0.397 Time consumed: 46.0853 s\n",
      "Epoch: 209 Train_loss: 1.014 Val_acc: 0.549 Time consumed: 45.6076 s\n",
      "Epoch: 210 Train_loss: 1.115 Val_acc: 0.458 Time consumed: 45.7531 s\n",
      "Epoch: 211 Train_loss: 1.090 Val_acc: 0.502 Time consumed: 45.9222 s\n",
      "Epoch: 212 Train_loss: 1.048 Val_acc: 0.473 Time consumed: 45.9264 s\n",
      "Epoch: 213 Train_loss: 0.973 Val_acc: 0.386 Time consumed: 45.9164 s\n",
      "Epoch: 214 Train_loss: 0.985 Val_acc: 0.508 Time consumed: 46.0173 s\n",
      "Epoch: 215 Train_loss: 0.972 Val_acc: 0.509 Time consumed: 45.5557 s\n",
      "Epoch: 216 Train_loss: 1.013 Val_acc: 0.552 Time consumed: 46.0318 s\n",
      "Epoch: 217 Train_loss: 0.942 Val_acc: 0.379 Time consumed: 46.0606 s\n",
      "Epoch: 218 Train_loss: 0.982 Val_acc: 0.548 Time consumed: 46.1190 s\n",
      "Epoch: 219 Train_loss: 0.989 Val_acc: 0.455 Time consumed: 45.7857 s\n",
      "Epoch: 220 Train_loss: 1.037 Val_acc: 0.402 Time consumed: 45.8641 s\n",
      "Epoch: 221 Train_loss: 1.063 Val_acc: 0.401 Time consumed: 46.1145 s\n",
      "Epoch: 222 Train_loss: 0.996 Val_acc: 0.552 Time consumed: 46.3186 s\n",
      "Epoch: 223 Train_loss: 0.988 Val_acc: 0.440 Time consumed: 46.3979 s\n",
      "Epoch: 224 Train_loss: 0.925 Val_acc: 0.617 Time consumed: 50.7157 s\n",
      "Epoch: 225 Train_loss: 1.008 Val_acc: 0.478 Time consumed: 46.0304 s\n",
      "Epoch: 226 Train_loss: 0.990 Val_acc: 0.546 Time consumed: 45.9719 s\n",
      "Epoch: 227 Train_loss: 0.941 Val_acc: 0.555 Time consumed: 45.7631 s\n",
      "Epoch: 228 Train_loss: 1.064 Val_acc: 0.473 Time consumed: 45.8208 s\n",
      "Epoch: 229 Train_loss: 1.001 Val_acc: 0.528 Time consumed: 45.8393 s\n",
      "Epoch: 230 Train_loss: 1.044 Val_acc: 0.447 Time consumed: 45.7411 s\n",
      "Epoch: 231 Train_loss: 0.999 Val_acc: 0.435 Time consumed: 45.9143 s\n",
      "Epoch: 232 Train_loss: 1.065 Val_acc: 0.547 Time consumed: 45.8633 s\n",
      "Epoch: 233 Train_loss: 0.927 Val_acc: 0.464 Time consumed: 45.6142 s\n",
      "Epoch: 234 Train_loss: 0.993 Val_acc: 0.535 Time consumed: 45.9928 s\n",
      "Epoch: 235 Train_loss: 1.095 Val_acc: 0.576 Time consumed: 45.8593 s\n",
      "Epoch: 236 Train_loss: 1.010 Val_acc: 0.541 Time consumed: 46.0792 s\n",
      "Epoch: 237 Train_loss: 1.053 Val_acc: 0.411 Time consumed: 45.8862 s\n",
      "Epoch: 238 Train_loss: 1.033 Val_acc: 0.463 Time consumed: 46.1944 s\n",
      "Epoch: 239 Train_loss: 1.039 Val_acc: 0.567 Time consumed: 45.6688 s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 240 Train_loss: 1.020 Val_acc: 0.513 Time consumed: 46.4582 s\n",
      "Epoch: 241 Train_loss: 0.852 Val_acc: 0.559 Time consumed: 45.7421 s\n",
      "Epoch: 242 Train_loss: 0.964 Val_acc: 0.607 Time consumed: 45.9295 s\n",
      "Epoch: 243 Train_loss: 0.971 Val_acc: 0.318 Time consumed: 45.8713 s\n",
      "Epoch: 244 Train_loss: 1.007 Val_acc: 0.525 Time consumed: 46.2159 s\n",
      "Epoch: 245 Train_loss: 0.954 Val_acc: 0.530 Time consumed: 45.9240 s\n",
      "Epoch: 246 Train_loss: 1.011 Val_acc: 0.545 Time consumed: 46.1537 s\n",
      "Epoch: 247 Train_loss: 1.095 Val_acc: 0.470 Time consumed: 46.1500 s\n",
      "Epoch: 248 Train_loss: 1.001 Val_acc: 0.597 Time consumed: 45.9522 s\n",
      "Epoch: 249 Train_loss: 1.011 Val_acc: 0.465 Time consumed: 46.2706 s\n",
      "Epoch: 250 Train_loss: 1.105 Val_acc: 0.468 Time consumed: 45.8997 s\n",
      "Epoch: 251 Train_loss: 0.984 Val_acc: 0.572 Time consumed: 46.6472 s\n",
      "Epoch: 252 Train_loss: 1.040 Val_acc: 0.565 Time consumed: 46.8730 s\n",
      "Epoch: 253 Train_loss: 1.002 Val_acc: 0.295 Time consumed: 46.4349 s\n",
      "Epoch: 254 Train_loss: 1.028 Val_acc: 0.560 Time consumed: 45.9002 s\n",
      "Epoch: 255 Train_loss: 0.955 Val_acc: 0.548 Time consumed: 46.3050 s\n",
      "Epoch: 256 Train_loss: 1.032 Val_acc: 0.335 Time consumed: 46.0499 s\n",
      "Epoch: 257 Train_loss: 1.099 Val_acc: 0.463 Time consumed: 46.0952 s\n",
      "Epoch: 258 Train_loss: 0.883 Val_acc: 0.384 Time consumed: 47.5172 s\n",
      "Epoch: 259 Train_loss: 0.976 Val_acc: 0.446 Time consumed: 45.9431 s\n",
      "Epoch: 260 Train_loss: 0.965 Val_acc: 0.548 Time consumed: 45.6971 s\n",
      "Epoch: 261 Train_loss: 1.040 Val_acc: 0.464 Time consumed: 45.7636 s\n",
      "Epoch: 262 Train_loss: 1.042 Val_acc: 0.423 Time consumed: 45.8056 s\n",
      "Epoch: 263 Train_loss: 1.017 Val_acc: 0.529 Time consumed: 45.7193 s\n",
      "Epoch: 264 Train_loss: 1.026 Val_acc: 0.480 Time consumed: 45.5927 s\n",
      "Epoch: 265 Train_loss: 1.041 Val_acc: 0.587 Time consumed: 45.7579 s\n",
      "Epoch: 266 Train_loss: 1.061 Val_acc: 0.555 Time consumed: 45.9893 s\n",
      "Epoch: 267 Train_loss: 0.953 Val_acc: 0.300 Time consumed: 45.9694 s\n",
      "Epoch: 268 Train_loss: 0.942 Val_acc: 0.340 Time consumed: 46.2792 s\n",
      "Epoch: 269 Train_loss: 1.021 Val_acc: 0.428 Time consumed: 46.1261 s\n",
      "Epoch: 270 Train_loss: 0.981 Val_acc: 0.461 Time consumed: 45.7456 s\n",
      "Epoch: 271 Train_loss: 1.018 Val_acc: 0.439 Time consumed: 46.0485 s\n",
      "Epoch: 272 Train_loss: 1.032 Val_acc: 0.419 Time consumed: 46.0313 s\n",
      "Epoch: 273 Train_loss: 1.039 Val_acc: 0.545 Time consumed: 45.9679 s\n",
      "Epoch: 274 Train_loss: 0.958 Val_acc: 0.588 Time consumed: 45.7505 s\n",
      "Epoch: 275 Train_loss: 0.987 Val_acc: 0.476 Time consumed: 46.1392 s\n",
      "Epoch: 276 Train_loss: 0.917 Val_acc: 0.552 Time consumed: 46.0031 s\n",
      "Epoch: 277 Train_loss: 0.944 Val_acc: 0.436 Time consumed: 46.6506 s\n",
      "Epoch: 278 Train_loss: 0.938 Val_acc: 0.461 Time consumed: 46.0056 s\n",
      "Epoch: 279 Train_loss: 0.961 Val_acc: 0.552 Time consumed: 46.4961 s\n",
      "Epoch: 280 Train_loss: 1.002 Val_acc: 0.511 Time consumed: 45.9416 s\n",
      "Epoch: 281 Train_loss: 1.042 Val_acc: 0.547 Time consumed: 45.9415 s\n",
      "Epoch: 282 Train_loss: 0.929 Val_acc: 0.526 Time consumed: 46.2000 s\n",
      "Epoch: 283 Train_loss: 0.959 Val_acc: 0.490 Time consumed: 46.3320 s\n",
      "Epoch: 284 Train_loss: 1.000 Val_acc: 0.489 Time consumed: 46.4803 s\n",
      "Epoch: 285 Train_loss: 0.869 Val_acc: 0.550 Time consumed: 46.3064 s\n",
      "Epoch: 286 Train_loss: 0.963 Val_acc: 0.340 Time consumed: 47.0259 s\n",
      "Epoch: 287 Train_loss: 0.968 Val_acc: 0.415 Time consumed: 48.1842 s\n",
      "Epoch: 288 Train_loss: 1.024 Val_acc: 0.447 Time consumed: 49.6402 s\n",
      "Epoch: 289 Train_loss: 0.946 Val_acc: 0.517 Time consumed: 48.8403 s\n",
      "Epoch: 290 Train_loss: 0.964 Val_acc: 0.417 Time consumed: 49.3241 s\n",
      "Epoch: 291 Train_loss: 0.920 Val_acc: 0.573 Time consumed: 48.7724 s\n",
      "Epoch: 292 Train_loss: 0.936 Val_acc: 0.518 Time consumed: 49.7074 s\n",
      "Epoch: 293 Train_loss: 0.989 Val_acc: 0.527 Time consumed: 47.9400 s\n",
      "Epoch: 294 Train_loss: 1.028 Val_acc: 0.572 Time consumed: 48.0191 s\n",
      "Epoch: 295 Train_loss: 0.952 Val_acc: 0.491 Time consumed: 47.4377 s\n",
      "Epoch: 296 Train_loss: 0.896 Val_acc: 0.539 Time consumed: 47.1409 s\n",
      "Epoch: 297 Train_loss: 0.952 Val_acc: 0.480 Time consumed: 45.8619 s\n",
      "Epoch: 298 Train_loss: 0.894 Val_acc: 0.401 Time consumed: 46.1450 s\n",
      "Epoch: 299 Train_loss: 0.929 Val_acc: 0.358 Time consumed: 46.1544 s\n",
      "Epoch: 300 Train_loss: 0.905 Val_acc: 0.417 Time consumed: 46.0929 s\n",
      "Epoch: 301 Train_loss: 0.938 Val_acc: 0.457 Time consumed: 46.0387 s\n",
      "Epoch: 302 Train_loss: 0.988 Val_acc: 0.514 Time consumed: 45.8355 s\n",
      "Epoch: 303 Train_loss: 1.011 Val_acc: 0.469 Time consumed: 45.7568 s\n",
      "Epoch: 304 Train_loss: 0.938 Val_acc: 0.502 Time consumed: 46.3834 s\n",
      "Epoch: 305 Train_loss: 0.875 Val_acc: 0.457 Time consumed: 46.2354 s\n",
      "Epoch: 306 Train_loss: 0.955 Val_acc: 0.463 Time consumed: 46.5068 s\n",
      "Epoch: 307 Train_loss: 0.952 Val_acc: 0.563 Time consumed: 45.9982 s\n",
      "Epoch: 308 Train_loss: 0.913 Val_acc: 0.442 Time consumed: 46.3741 s\n",
      "Epoch: 309 Train_loss: 1.017 Val_acc: 0.275 Time consumed: 45.9607 s\n",
      "Epoch: 310 Train_loss: 0.945 Val_acc: 0.485 Time consumed: 46.1241 s\n",
      "Epoch: 311 Train_loss: 0.980 Val_acc: 0.529 Time consumed: 46.0368 s\n",
      "Epoch: 312 Train_loss: 1.022 Val_acc: 0.428 Time consumed: 46.0076 s\n",
      "Epoch: 313 Train_loss: 0.979 Val_acc: 0.461 Time consumed: 46.1102 s\n",
      "Epoch: 314 Train_loss: 0.916 Val_acc: 0.485 Time consumed: 45.9905 s\n",
      "Epoch: 315 Train_loss: 0.962 Val_acc: 0.358 Time consumed: 46.1856 s\n",
      "Epoch: 316 Train_loss: 0.896 Val_acc: 0.335 Time consumed: 46.1262 s\n",
      "Epoch: 317 Train_loss: 0.957 Val_acc: 0.488 Time consumed: 45.9056 s\n",
      "Epoch: 318 Train_loss: 0.937 Val_acc: 0.410 Time consumed: 46.3460 s\n",
      "Epoch: 319 Train_loss: 0.875 Val_acc: 0.250 Time consumed: 48.8153 s\n",
      "Epoch: 320 Train_loss: 0.904 Val_acc: 0.396 Time consumed: 50.0293 s\n",
      "Epoch: 321 Train_loss: 0.944 Val_acc: 0.409 Time consumed: 48.6163 s\n",
      "Epoch: 322 Train_loss: 0.948 Val_acc: 0.495 Time consumed: 48.8435 s\n",
      "Epoch: 323 Train_loss: 0.816 Val_acc: 0.571 Time consumed: 48.1049 s\n",
      "Epoch: 324 Train_loss: 0.889 Val_acc: 0.324 Time consumed: 47.6370 s\n",
      "Epoch: 325 Train_loss: 0.958 Val_acc: 0.435 Time consumed: 47.7359 s\n",
      "Epoch: 326 Train_loss: 0.947 Val_acc: 0.495 Time consumed: 48.2565 s\n",
      "Epoch: 327 Train_loss: 0.998 Val_acc: 0.625 Time consumed: 49.5839 s\n",
      "Epoch: 328 Train_loss: 0.840 Val_acc: 0.378 Time consumed: 45.4288 s\n",
      "Epoch: 329 Train_loss: 0.998 Val_acc: 0.332 Time consumed: 45.4214 s\n",
      "Epoch: 330 Train_loss: 0.937 Val_acc: 0.476 Time consumed: 45.2616 s\n",
      "Epoch: 331 Train_loss: 0.876 Val_acc: 0.523 Time consumed: 45.3430 s\n",
      "Epoch: 332 Train_loss: 0.973 Val_acc: 0.576 Time consumed: 45.4204 s\n",
      "Epoch: 333 Train_loss: 0.908 Val_acc: 0.344 Time consumed: 45.4586 s\n",
      "Epoch: 334 Train_loss: 0.863 Val_acc: 0.434 Time consumed: 45.2307 s\n",
      "Epoch: 335 Train_loss: 0.971 Val_acc: 0.444 Time consumed: 45.3039 s\n",
      "Epoch: 336 Train_loss: 0.866 Val_acc: 0.559 Time consumed: 45.5619 s\n",
      "Epoch: 337 Train_loss: 0.911 Val_acc: 0.442 Time consumed: 45.3460 s\n",
      "Epoch: 338 Train_loss: 0.928 Val_acc: 0.447 Time consumed: 45.5374 s\n",
      "Epoch: 339 Train_loss: 0.963 Val_acc: 0.423 Time consumed: 45.2160 s\n",
      "Epoch: 340 Train_loss: 1.012 Val_acc: 0.515 Time consumed: 45.5900 s\n",
      "Epoch: 341 Train_loss: 0.905 Val_acc: 0.301 Time consumed: 45.2439 s\n",
      "Epoch: 342 Train_loss: 0.948 Val_acc: 0.460 Time consumed: 45.2219 s\n",
      "Epoch: 343 Train_loss: 1.001 Val_acc: 0.465 Time consumed: 44.9847 s\n",
      "Epoch: 344 Train_loss: 0.973 Val_acc: 0.419 Time consumed: 45.5710 s\n",
      "Epoch: 345 Train_loss: 0.892 Val_acc: 0.566 Time consumed: 45.5938 s\n",
      "Epoch: 346 Train_loss: 0.927 Val_acc: 0.556 Time consumed: 45.2762 s\n",
      "Epoch: 347 Train_loss: 0.970 Val_acc: 0.509 Time consumed: 45.4541 s\n",
      "Epoch: 348 Train_loss: 0.978 Val_acc: 0.557 Time consumed: 45.5446 s\n",
      "Epoch: 349 Train_loss: 0.895 Val_acc: 0.457 Time consumed: 45.6266 s\n",
      "Epoch: 350 Train_loss: 0.860 Val_acc: 0.369 Time consumed: 45.5223 s\n",
      "Epoch: 351 Train_loss: 1.020 Val_acc: 0.457 Time consumed: 45.4536 s\n",
      "Epoch: 352 Train_loss: 0.978 Val_acc: 0.378 Time consumed: 45.1496 s\n",
      "Epoch: 353 Train_loss: 0.942 Val_acc: 0.517 Time consumed: 45.2993 s\n",
      "Epoch: 354 Train_loss: 0.961 Val_acc: 0.492 Time consumed: 45.3292 s\n",
      "Epoch: 355 Train_loss: 0.948 Val_acc: 0.544 Time consumed: 45.5287 s\n",
      "Epoch: 356 Train_loss: 0.910 Val_acc: 0.487 Time consumed: 45.5347 s\n",
      "Epoch: 357 Train_loss: 0.990 Val_acc: 0.230 Time consumed: 45.4838 s\n",
      "Epoch: 358 Train_loss: 0.880 Val_acc: 0.516 Time consumed: 45.4686 s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 359 Train_loss: 0.950 Val_acc: 0.575 Time consumed: 45.4959 s\n",
      "Epoch: 360 Train_loss: 0.958 Val_acc: 0.524 Time consumed: 45.7540 s\n",
      "Epoch: 361 Train_loss: 0.973 Val_acc: 0.541 Time consumed: 47.4930 s\n",
      "Epoch: 362 Train_loss: 0.930 Val_acc: 0.396 Time consumed: 48.2276 s\n",
      "Epoch: 363 Train_loss: 0.893 Val_acc: 0.541 Time consumed: 49.7729 s\n",
      "Epoch: 364 Train_loss: 0.951 Val_acc: 0.389 Time consumed: 49.1746 s\n",
      "Epoch: 365 Train_loss: 0.929 Val_acc: 0.651 Time consumed: 54.6844 s\n",
      "Epoch: 366 Train_loss: 0.953 Val_acc: 0.491 Time consumed: 47.5244 s\n",
      "Epoch: 367 Train_loss: 0.979 Val_acc: 0.409 Time consumed: 46.0469 s\n",
      "Epoch: 368 Train_loss: 0.908 Val_acc: 0.451 Time consumed: 46.2385 s\n",
      "Epoch: 369 Train_loss: 0.936 Val_acc: 0.532 Time consumed: 46.2966 s\n",
      "Epoch: 370 Train_loss: 0.864 Val_acc: 0.421 Time consumed: 45.9028 s\n",
      "Epoch: 371 Train_loss: 0.923 Val_acc: 0.499 Time consumed: 46.2988 s\n",
      "Epoch: 372 Train_loss: 0.930 Val_acc: 0.468 Time consumed: 45.9436 s\n",
      "Epoch: 373 Train_loss: 0.975 Val_acc: 0.477 Time consumed: 46.5337 s\n",
      "Epoch: 374 Train_loss: 0.946 Val_acc: 0.480 Time consumed: 46.1066 s\n",
      "Epoch: 375 Train_loss: 0.917 Val_acc: 0.377 Time consumed: 46.3481 s\n",
      "Epoch: 376 Train_loss: 0.922 Val_acc: 0.521 Time consumed: 45.9067 s\n",
      "Epoch: 377 Train_loss: 0.906 Val_acc: 0.460 Time consumed: 45.8625 s\n",
      "Epoch: 378 Train_loss: 0.893 Val_acc: 0.603 Time consumed: 45.9509 s\n",
      "Epoch: 379 Train_loss: 0.858 Val_acc: 0.444 Time consumed: 46.2535 s\n",
      "Epoch: 380 Train_loss: 0.875 Val_acc: 0.406 Time consumed: 46.1621 s\n",
      "Epoch: 381 Train_loss: 0.898 Val_acc: 0.450 Time consumed: 46.5338 s\n",
      "Epoch: 382 Train_loss: 0.902 Val_acc: 0.299 Time consumed: 46.3964 s\n",
      "Epoch: 383 Train_loss: 0.941 Val_acc: 0.418 Time consumed: 46.2393 s\n",
      "Epoch: 384 Train_loss: 0.973 Val_acc: 0.443 Time consumed: 46.3699 s\n",
      "Epoch: 385 Train_loss: 0.899 Val_acc: 0.584 Time consumed: 46.1734 s\n",
      "Epoch: 386 Train_loss: 0.894 Val_acc: 0.490 Time consumed: 46.1759 s\n",
      "Epoch: 387 Train_loss: 0.926 Val_acc: 0.568 Time consumed: 46.2743 s\n",
      "Epoch: 388 Train_loss: 0.903 Val_acc: 0.517 Time consumed: 46.1748 s\n",
      "Epoch: 389 Train_loss: 0.866 Val_acc: 0.328 Time consumed: 46.0878 s\n",
      "Epoch: 390 Train_loss: 0.934 Val_acc: 0.411 Time consumed: 46.1970 s\n",
      "Epoch: 391 Train_loss: 0.855 Val_acc: 0.538 Time consumed: 46.2792 s\n",
      "Epoch: 392 Train_loss: 0.880 Val_acc: 0.591 Time consumed: 45.9967 s\n",
      "Epoch: 393 Train_loss: 0.919 Val_acc: 0.466 Time consumed: 46.1205 s\n",
      "Epoch: 394 Train_loss: 0.939 Val_acc: 0.596 Time consumed: 46.2309 s\n",
      "Epoch: 395 Train_loss: 0.940 Val_acc: 0.481 Time consumed: 46.3653 s\n",
      "Epoch: 396 Train_loss: 0.978 Val_acc: 0.622 Time consumed: 45.9593 s\n",
      "Epoch: 397 Train_loss: 0.912 Val_acc: 0.356 Time consumed: 45.7965 s\n",
      "Epoch: 398 Train_loss: 1.006 Val_acc: 0.410 Time consumed: 46.0577 s\n",
      "Epoch: 399 Train_loss: 0.984 Val_acc: 0.482 Time consumed: 45.8419 s\n",
      "Epoch: 400 Train_loss: 0.977 Val_acc: 0.592 Time consumed: 46.1872 s\n",
      "Epoch: 401 Train_loss: 1.022 Val_acc: 0.502 Time consumed: 46.2309 s\n",
      "Epoch: 402 Train_loss: 0.928 Val_acc: 0.496 Time consumed: 46.2251 s\n",
      "Epoch: 403 Train_loss: 0.915 Val_acc: 0.535 Time consumed: 46.0858 s\n",
      "Epoch: 404 Train_loss: 0.999 Val_acc: 0.636 Time consumed: 46.0799 s\n",
      "Epoch: 405 Train_loss: 0.886 Val_acc: 0.453 Time consumed: 46.3224 s\n",
      "Epoch: 406 Train_loss: 0.981 Val_acc: 0.400 Time consumed: 46.0287 s\n",
      "Epoch: 407 Train_loss: 0.865 Val_acc: 0.340 Time consumed: 46.1835 s\n",
      "Epoch: 408 Train_loss: 0.937 Val_acc: 0.392 Time consumed: 45.9803 s\n",
      "Epoch: 409 Train_loss: 0.960 Val_acc: 0.497 Time consumed: 46.5532 s\n",
      "Epoch: 410 Train_loss: 0.915 Val_acc: 0.530 Time consumed: 46.0568 s\n",
      "Epoch: 411 Train_loss: 0.976 Val_acc: 0.422 Time consumed: 46.2676 s\n",
      "Epoch: 412 Train_loss: 0.933 Val_acc: 0.575 Time consumed: 46.0861 s\n",
      "Epoch: 413 Train_loss: 0.934 Val_acc: 0.387 Time consumed: 45.9890 s\n",
      "Epoch: 414 Train_loss: 0.896 Val_acc: 0.402 Time consumed: 46.0307 s\n",
      "Epoch: 415 Train_loss: 0.887 Val_acc: 0.348 Time consumed: 46.0812 s\n",
      "Epoch: 416 Train_loss: 0.883 Val_acc: 0.579 Time consumed: 46.2935 s\n",
      "Epoch: 417 Train_loss: 0.969 Val_acc: 0.567 Time consumed: 46.4523 s\n",
      "Epoch: 418 Train_loss: 0.892 Val_acc: 0.550 Time consumed: 46.8040 s\n",
      "Epoch: 419 Train_loss: 0.870 Val_acc: 0.559 Time consumed: 46.2398 s\n",
      "Epoch: 420 Train_loss: 0.867 Val_acc: 0.517 Time consumed: 46.2276 s\n",
      "Epoch: 421 Train_loss: 0.988 Val_acc: 0.252 Time consumed: 46.2928 s\n",
      "Epoch: 422 Train_loss: 0.916 Val_acc: 0.480 Time consumed: 45.9744 s\n",
      "Epoch: 423 Train_loss: 0.948 Val_acc: 0.452 Time consumed: 46.4828 s\n",
      "Epoch: 424 Train_loss: 1.043 Val_acc: 0.528 Time consumed: 46.0801 s\n",
      "Epoch: 425 Train_loss: 0.970 Val_acc: 0.585 Time consumed: 45.9863 s\n",
      "Epoch: 426 Train_loss: 0.853 Val_acc: 0.453 Time consumed: 46.2017 s\n",
      "Epoch: 427 Train_loss: 0.923 Val_acc: 0.488 Time consumed: 45.9288 s\n",
      "Epoch: 428 Train_loss: 0.860 Val_acc: 0.457 Time consumed: 46.2158 s\n",
      "Epoch: 429 Train_loss: 0.982 Val_acc: 0.559 Time consumed: 45.9180 s\n",
      "Epoch: 430 Train_loss: 0.868 Val_acc: 0.612 Time consumed: 47.5243 s\n",
      "Epoch: 431 Train_loss: 0.890 Val_acc: 0.608 Time consumed: 46.2065 s\n",
      "Epoch: 432 Train_loss: 0.850 Val_acc: 0.349 Time consumed: 46.3362 s\n",
      "Epoch: 433 Train_loss: 0.982 Val_acc: 0.434 Time consumed: 45.8444 s\n",
      "Epoch: 434 Train_loss: 0.940 Val_acc: 0.657 Time consumed: 50.0407 s\n",
      "Epoch: 435 Train_loss: 1.021 Val_acc: 0.374 Time consumed: 46.0841 s\n",
      "Epoch: 436 Train_loss: 0.853 Val_acc: 0.514 Time consumed: 45.9027 s\n",
      "Epoch: 437 Train_loss: 0.767 Val_acc: 0.304 Time consumed: 46.1669 s\n",
      "Epoch: 438 Train_loss: 0.903 Val_acc: 0.536 Time consumed: 45.7143 s\n",
      "Epoch: 439 Train_loss: 0.871 Val_acc: 0.631 Time consumed: 46.2038 s\n",
      "Epoch: 440 Train_loss: 0.976 Val_acc: 0.522 Time consumed: 45.8301 s\n",
      "Epoch: 441 Train_loss: 0.892 Val_acc: 0.520 Time consumed: 46.2485 s\n",
      "Epoch: 442 Train_loss: 0.957 Val_acc: 0.515 Time consumed: 45.9628 s\n",
      "Epoch: 443 Train_loss: 0.916 Val_acc: 0.549 Time consumed: 46.2631 s\n",
      "Epoch: 444 Train_loss: 1.085 Val_acc: 0.535 Time consumed: 46.3513 s\n",
      "Epoch: 445 Train_loss: 0.852 Val_acc: 0.416 Time consumed: 45.5392 s\n",
      "Epoch: 446 Train_loss: 0.958 Val_acc: 0.516 Time consumed: 46.4613 s\n",
      "Epoch: 447 Train_loss: 0.943 Val_acc: 0.396 Time consumed: 46.1205 s\n",
      "Epoch: 448 Train_loss: 1.014 Val_acc: 0.400 Time consumed: 46.2520 s\n",
      "Epoch: 449 Train_loss: 0.971 Val_acc: 0.509 Time consumed: 46.3251 s\n",
      "Epoch: 450 Train_loss: 0.925 Val_acc: 0.607 Time consumed: 45.8791 s\n",
      "Epoch: 451 Train_loss: 0.958 Val_acc: 0.279 Time consumed: 45.8049 s\n",
      "Epoch: 452 Train_loss: 0.826 Val_acc: 0.562 Time consumed: 46.3644 s\n",
      "Epoch: 453 Train_loss: 0.935 Val_acc: 0.580 Time consumed: 45.9515 s\n",
      "Epoch: 454 Train_loss: 0.913 Val_acc: 0.510 Time consumed: 46.2381 s\n",
      "Epoch: 455 Train_loss: 0.948 Val_acc: 0.551 Time consumed: 46.2573 s\n",
      "Epoch: 456 Train_loss: 0.907 Val_acc: 0.402 Time consumed: 45.9005 s\n",
      "Epoch: 457 Train_loss: 1.005 Val_acc: 0.537 Time consumed: 46.0656 s\n",
      "Epoch: 458 Train_loss: 0.978 Val_acc: 0.579 Time consumed: 46.3890 s\n",
      "Epoch: 459 Train_loss: 0.840 Val_acc: 0.577 Time consumed: 45.9780 s\n",
      "Epoch: 460 Train_loss: 0.916 Val_acc: 0.575 Time consumed: 45.8598 s\n",
      "Epoch: 461 Train_loss: 0.885 Val_acc: 0.408 Time consumed: 46.2079 s\n",
      "Epoch: 462 Train_loss: 0.939 Val_acc: 0.505 Time consumed: 46.0899 s\n",
      "Epoch: 463 Train_loss: 0.861 Val_acc: 0.428 Time consumed: 46.1661 s\n",
      "Epoch: 464 Train_loss: 0.898 Val_acc: 0.443 Time consumed: 46.2995 s\n",
      "Epoch: 465 Train_loss: 0.866 Val_acc: 0.391 Time consumed: 46.5955 s\n",
      "Epoch: 466 Train_loss: 0.880 Val_acc: 0.500 Time consumed: 46.2548 s\n",
      "Epoch: 467 Train_loss: 0.899 Val_acc: 0.411 Time consumed: 46.3833 s\n",
      "Epoch: 468 Train_loss: 0.906 Val_acc: 0.576 Time consumed: 47.0422 s\n",
      "Epoch: 469 Train_loss: 0.923 Val_acc: 0.467 Time consumed: 46.3459 s\n",
      "Epoch: 470 Train_loss: 0.946 Val_acc: 0.318 Time consumed: 46.0921 s\n",
      "Epoch: 471 Train_loss: 0.837 Val_acc: 0.608 Time consumed: 46.0838 s\n",
      "Epoch: 472 Train_loss: 0.931 Val_acc: 0.413 Time consumed: 46.1444 s\n",
      "Epoch: 473 Train_loss: 0.837 Val_acc: 0.441 Time consumed: 46.3140 s\n",
      "Epoch: 474 Train_loss: 0.873 Val_acc: 0.574 Time consumed: 46.0687 s\n",
      "Epoch: 475 Train_loss: 0.952 Val_acc: 0.321 Time consumed: 45.9705 s\n",
      "Epoch: 476 Train_loss: 0.888 Val_acc: 0.515 Time consumed: 46.1597 s\n",
      "Epoch: 477 Train_loss: 0.894 Val_acc: 0.521 Time consumed: 46.2244 s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 478 Train_loss: 0.893 Val_acc: 0.347 Time consumed: 46.4332 s\n",
      "Epoch: 479 Train_loss: 0.845 Val_acc: 0.508 Time consumed: 46.4397 s\n",
      "Epoch: 480 Train_loss: 0.832 Val_acc: 0.362 Time consumed: 45.9907 s\n",
      "Epoch: 481 Train_loss: 0.960 Val_acc: 0.284 Time consumed: 46.2850 s\n",
      "Epoch: 482 Train_loss: 0.940 Val_acc: 0.512 Time consumed: 45.7883 s\n",
      "Epoch: 483 Train_loss: 0.925 Val_acc: 0.303 Time consumed: 45.9851 s\n",
      "Epoch: 484 Train_loss: 0.988 Val_acc: 0.455 Time consumed: 46.4063 s\n",
      "Epoch: 485 Train_loss: 0.837 Val_acc: 0.534 Time consumed: 46.1327 s\n",
      "Epoch: 486 Train_loss: 0.940 Val_acc: 0.568 Time consumed: 45.8426 s\n",
      "Epoch: 487 Train_loss: 0.837 Val_acc: 0.557 Time consumed: 46.3156 s\n",
      "Epoch: 488 Train_loss: 0.896 Val_acc: 0.587 Time consumed: 46.1256 s\n",
      "Epoch: 489 Train_loss: 0.877 Val_acc: 0.571 Time consumed: 46.3854 s\n",
      "Epoch: 490 Train_loss: 0.870 Val_acc: 0.517 Time consumed: 46.4247 s\n",
      "Epoch: 491 Train_loss: 0.835 Val_acc: 0.340 Time consumed: 46.3177 s\n",
      "Epoch: 492 Train_loss: 0.867 Val_acc: 0.533 Time consumed: 46.3795 s\n",
      "Epoch: 493 Train_loss: 0.885 Val_acc: 0.584 Time consumed: 46.2458 s\n",
      "Epoch: 494 Train_loss: 0.820 Val_acc: 0.619 Time consumed: 45.9572 s\n",
      "Epoch: 495 Train_loss: 0.913 Val_acc: 0.421 Time consumed: 45.9750 s\n",
      "Epoch: 496 Train_loss: 0.868 Val_acc: 0.522 Time consumed: 46.2991 s\n",
      "Epoch: 497 Train_loss: 0.946 Val_acc: 0.559 Time consumed: 46.1264 s\n",
      "Epoch: 498 Train_loss: 0.923 Val_acc: 0.508 Time consumed: 46.2027 s\n",
      "Epoch: 499 Train_loss: 0.979 Val_acc: 0.511 Time consumed: 46.4424 s\n",
      "Epoch: 500 Train_loss: 0.915 Val_acc: 0.473 Time consumed: 46.1903 s\n",
      "Epoch: 501 Train_loss: 0.860 Val_acc: 0.576 Time consumed: 46.4362 s\n",
      "Epoch: 502 Train_loss: 0.890 Val_acc: 0.470 Time consumed: 47.2825 s\n",
      "Epoch: 503 Train_loss: 0.807 Val_acc: 0.527 Time consumed: 46.3447 s\n",
      "Epoch: 504 Train_loss: 0.836 Val_acc: 0.614 Time consumed: 46.2647 s\n",
      "Epoch: 505 Train_loss: 0.953 Val_acc: 0.452 Time consumed: 45.8597 s\n",
      "Epoch: 506 Train_loss: 0.806 Val_acc: 0.530 Time consumed: 46.1076 s\n",
      "Epoch: 507 Train_loss: 0.916 Val_acc: 0.464 Time consumed: 46.0173 s\n",
      "Epoch: 508 Train_loss: 0.894 Val_acc: 0.478 Time consumed: 45.9898 s\n",
      "Epoch: 509 Train_loss: 0.813 Val_acc: 0.402 Time consumed: 45.9294 s\n",
      "Epoch: 510 Train_loss: 0.881 Val_acc: 0.522 Time consumed: 46.2393 s\n",
      "Epoch: 511 Train_loss: 0.849 Val_acc: 0.594 Time consumed: 46.4087 s\n",
      "Epoch: 512 Train_loss: 0.877 Val_acc: 0.546 Time consumed: 45.8809 s\n",
      "Epoch: 513 Train_loss: 0.932 Val_acc: 0.463 Time consumed: 46.4136 s\n",
      "Epoch: 514 Train_loss: 0.878 Val_acc: 0.480 Time consumed: 46.1109 s\n",
      "Epoch: 515 Train_loss: 0.908 Val_acc: 0.464 Time consumed: 45.9485 s\n",
      "Epoch: 516 Train_loss: 0.897 Val_acc: 0.570 Time consumed: 46.2109 s\n",
      "Epoch: 517 Train_loss: 0.878 Val_acc: 0.531 Time consumed: 46.0341 s\n",
      "Epoch: 518 Train_loss: 0.920 Val_acc: 0.483 Time consumed: 46.1459 s\n",
      "Epoch: 519 Train_loss: 0.851 Val_acc: 0.452 Time consumed: 45.9643 s\n",
      "Epoch: 520 Train_loss: 0.911 Val_acc: 0.552 Time consumed: 46.1669 s\n",
      "Epoch: 521 Train_loss: 0.830 Val_acc: 0.413 Time consumed: 46.3742 s\n",
      "Epoch: 522 Train_loss: 0.895 Val_acc: 0.557 Time consumed: 45.9035 s\n",
      "Epoch: 523 Train_loss: 0.962 Val_acc: 0.444 Time consumed: 46.1939 s\n",
      "Epoch: 524 Train_loss: 0.897 Val_acc: 0.571 Time consumed: 46.1430 s\n",
      "Epoch: 525 Train_loss: 0.931 Val_acc: 0.368 Time consumed: 46.0760 s\n",
      "Epoch: 526 Train_loss: 0.873 Val_acc: 0.476 Time consumed: 46.2088 s\n",
      "Epoch: 527 Train_loss: 0.942 Val_acc: 0.587 Time consumed: 46.4910 s\n",
      "Epoch: 528 Train_loss: 0.885 Val_acc: 0.466 Time consumed: 46.3310 s\n",
      "Epoch: 529 Train_loss: 0.909 Val_acc: 0.419 Time consumed: 46.2277 s\n",
      "Epoch: 530 Train_loss: 0.949 Val_acc: 0.660 Time consumed: 51.0707 s\n",
      "Epoch: 531 Train_loss: 0.904 Val_acc: 0.390 Time consumed: 46.0355 s\n",
      "Epoch: 532 Train_loss: 0.877 Val_acc: 0.410 Time consumed: 46.1309 s\n",
      "Epoch: 533 Train_loss: 0.815 Val_acc: 0.445 Time consumed: 45.9919 s\n",
      "Epoch: 534 Train_loss: 0.952 Val_acc: 0.430 Time consumed: 46.1578 s\n",
      "Epoch: 535 Train_loss: 0.888 Val_acc: 0.525 Time consumed: 45.9415 s\n",
      "Epoch: 536 Train_loss: 0.924 Val_acc: 0.433 Time consumed: 46.0401 s\n",
      "Epoch: 537 Train_loss: 0.898 Val_acc: 0.366 Time consumed: 46.1050 s\n",
      "Epoch: 538 Train_loss: 0.881 Val_acc: 0.602 Time consumed: 46.3475 s\n",
      "Epoch: 539 Train_loss: 0.808 Val_acc: 0.612 Time consumed: 46.1265 s\n",
      "Epoch: 540 Train_loss: 0.883 Val_acc: 0.541 Time consumed: 46.0699 s\n",
      "Epoch: 541 Train_loss: 0.905 Val_acc: 0.416 Time consumed: 46.3671 s\n",
      "Epoch: 542 Train_loss: 0.853 Val_acc: 0.438 Time consumed: 46.1762 s\n",
      "Epoch: 543 Train_loss: 0.855 Val_acc: 0.396 Time consumed: 46.1387 s\n",
      "Epoch: 544 Train_loss: 0.880 Val_acc: 0.557 Time consumed: 46.0158 s\n",
      "Epoch: 545 Train_loss: 0.910 Val_acc: 0.449 Time consumed: 46.0420 s\n",
      "Epoch: 546 Train_loss: 0.789 Val_acc: 0.531 Time consumed: 46.0168 s\n",
      "Epoch: 547 Train_loss: 0.936 Val_acc: 0.556 Time consumed: 46.0307 s\n",
      "Epoch: 548 Train_loss: 0.843 Val_acc: 0.496 Time consumed: 45.9040 s\n",
      "Epoch: 549 Train_loss: 0.874 Val_acc: 0.582 Time consumed: 46.2742 s\n",
      "Epoch: 550 Train_loss: 0.948 Val_acc: 0.590 Time consumed: 46.2332 s\n",
      "Epoch: 551 Train_loss: 0.925 Val_acc: 0.584 Time consumed: 46.0452 s\n",
      "Epoch: 552 Train_loss: 0.873 Val_acc: 0.607 Time consumed: 46.3611 s\n",
      "Epoch: 553 Train_loss: 0.782 Val_acc: 0.522 Time consumed: 46.3770 s\n",
      "Epoch: 554 Train_loss: 0.940 Val_acc: 0.605 Time consumed: 46.3794 s\n",
      "Epoch: 555 Train_loss: 0.924 Val_acc: 0.466 Time consumed: 46.4559 s\n",
      "Epoch: 556 Train_loss: 0.978 Val_acc: 0.389 Time consumed: 45.9340 s\n",
      "Epoch: 557 Train_loss: 0.919 Val_acc: 0.483 Time consumed: 46.1049 s\n",
      "Epoch: 558 Train_loss: 0.888 Val_acc: 0.624 Time consumed: 46.1627 s\n",
      "Epoch: 559 Train_loss: 0.907 Val_acc: 0.276 Time consumed: 46.2100 s\n",
      "Epoch: 560 Train_loss: 0.900 Val_acc: 0.402 Time consumed: 46.2778 s\n",
      "Epoch: 561 Train_loss: 0.843 Val_acc: 0.628 Time consumed: 45.9353 s\n",
      "Epoch: 562 Train_loss: 0.864 Val_acc: 0.556 Time consumed: 45.8322 s\n",
      "Epoch: 563 Train_loss: 0.949 Val_acc: 0.368 Time consumed: 46.2061 s\n",
      "Epoch: 564 Train_loss: 0.902 Val_acc: 0.570 Time consumed: 47.1788 s\n",
      "Epoch: 565 Train_loss: 0.979 Val_acc: 0.531 Time consumed: 46.0053 s\n",
      "Epoch: 566 Train_loss: 0.896 Val_acc: 0.557 Time consumed: 45.8641 s\n",
      "Epoch: 567 Train_loss: 0.839 Val_acc: 0.538 Time consumed: 46.0520 s\n",
      "Epoch: 568 Train_loss: 0.838 Val_acc: 0.314 Time consumed: 45.8948 s\n",
      "Epoch: 569 Train_loss: 0.913 Val_acc: 0.534 Time consumed: 46.0169 s\n",
      "Epoch: 570 Train_loss: 0.871 Val_acc: 0.445 Time consumed: 45.9138 s\n",
      "Epoch: 571 Train_loss: 0.795 Val_acc: 0.590 Time consumed: 46.3910 s\n",
      "Epoch: 572 Train_loss: 0.839 Val_acc: 0.462 Time consumed: 45.9403 s\n",
      "Epoch: 573 Train_loss: 0.843 Val_acc: 0.525 Time consumed: 46.0945 s\n",
      "Epoch: 574 Train_loss: 0.947 Val_acc: 0.529 Time consumed: 46.2758 s\n",
      "Epoch: 575 Train_loss: 0.867 Val_acc: 0.425 Time consumed: 46.1981 s\n",
      "Epoch: 576 Train_loss: 0.959 Val_acc: 0.526 Time consumed: 46.1190 s\n",
      "Epoch: 577 Train_loss: 0.932 Val_acc: 0.576 Time consumed: 46.0385 s\n",
      "Epoch: 578 Train_loss: 0.764 Val_acc: 0.481 Time consumed: 45.9187 s\n",
      "Epoch: 579 Train_loss: 0.933 Val_acc: 0.498 Time consumed: 45.9802 s\n",
      "Epoch: 580 Train_loss: 0.863 Val_acc: 0.492 Time consumed: 46.5038 s\n",
      "Epoch: 581 Train_loss: 0.845 Val_acc: 0.450 Time consumed: 45.8647 s\n",
      "Epoch: 582 Train_loss: 0.755 Val_acc: 0.630 Time consumed: 46.1708 s\n",
      "Epoch: 583 Train_loss: 0.817 Val_acc: 0.575 Time consumed: 46.2832 s\n",
      "Epoch: 584 Train_loss: 0.960 Val_acc: 0.385 Time consumed: 46.2611 s\n",
      "Epoch: 585 Train_loss: 0.871 Val_acc: 0.461 Time consumed: 46.2102 s\n",
      "Epoch: 586 Train_loss: 0.871 Val_acc: 0.564 Time consumed: 46.5707 s\n",
      "Epoch: 587 Train_loss: 0.839 Val_acc: 0.524 Time consumed: 46.4626 s\n",
      "Epoch: 588 Train_loss: 0.807 Val_acc: 0.492 Time consumed: 46.5233 s\n",
      "Epoch: 589 Train_loss: 0.836 Val_acc: 0.376 Time consumed: 46.1370 s\n",
      "Epoch: 590 Train_loss: 0.842 Val_acc: 0.484 Time consumed: 46.1062 s\n",
      "Epoch: 591 Train_loss: 0.884 Val_acc: 0.432 Time consumed: 46.2637 s\n",
      "Epoch: 592 Train_loss: 0.886 Val_acc: 0.615 Time consumed: 46.1523 s\n",
      "Epoch: 593 Train_loss: 0.841 Val_acc: 0.534 Time consumed: 46.1080 s\n",
      "Epoch: 594 Train_loss: 0.910 Val_acc: 0.434 Time consumed: 46.5980 s\n",
      "Epoch: 595 Train_loss: 0.945 Val_acc: 0.594 Time consumed: 46.4927 s\n",
      "Epoch: 596 Train_loss: 0.905 Val_acc: 0.308 Time consumed: 46.2171 s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 597 Train_loss: 0.830 Val_acc: 0.573 Time consumed: 46.2652 s\n",
      "Epoch: 598 Train_loss: 0.913 Val_acc: 0.359 Time consumed: 47.4344 s\n",
      "Epoch: 599 Train_loss: 0.914 Val_acc: 0.532 Time consumed: 45.8091 s\n",
      "Epoch: 600 Train_loss: 0.900 Val_acc: 0.629 Time consumed: 45.7844 s\n",
      "Epoch: 601 Train_loss: 0.943 Val_acc: 0.510 Time consumed: 45.8016 s\n",
      "Epoch: 602 Train_loss: 0.807 Val_acc: 0.515 Time consumed: 46.2682 s\n",
      "Epoch: 603 Train_loss: 0.917 Val_acc: 0.364 Time consumed: 45.9395 s\n",
      "Epoch: 604 Train_loss: 0.951 Val_acc: 0.550 Time consumed: 46.4709 s\n",
      "Epoch: 605 Train_loss: 0.878 Val_acc: 0.679 Time consumed: 50.4422 s\n",
      "Epoch: 606 Train_loss: 0.912 Val_acc: 0.457 Time consumed: 46.0897 s\n",
      "Epoch: 607 Train_loss: 0.857 Val_acc: 0.468 Time consumed: 45.8477 s\n",
      "Epoch: 608 Train_loss: 0.799 Val_acc: 0.340 Time consumed: 45.9857 s\n",
      "Epoch: 609 Train_loss: 0.944 Val_acc: 0.313 Time consumed: 45.7864 s\n",
      "Epoch: 610 Train_loss: 0.889 Val_acc: 0.288 Time consumed: 46.4289 s\n",
      "Epoch: 611 Train_loss: 0.838 Val_acc: 0.574 Time consumed: 46.6194 s\n",
      "Epoch: 612 Train_loss: 0.890 Val_acc: 0.480 Time consumed: 45.8004 s\n",
      "Epoch: 613 Train_loss: 0.889 Val_acc: 0.384 Time consumed: 46.0924 s\n",
      "Epoch: 614 Train_loss: 0.864 Val_acc: 0.494 Time consumed: 45.9455 s\n",
      "Epoch: 615 Train_loss: 0.875 Val_acc: 0.631 Time consumed: 46.0576 s\n",
      "Epoch: 616 Train_loss: 0.811 Val_acc: 0.490 Time consumed: 46.3266 s\n",
      "Epoch: 617 Train_loss: 0.806 Val_acc: 0.580 Time consumed: 46.0617 s\n",
      "Epoch: 618 Train_loss: 0.968 Val_acc: 0.305 Time consumed: 45.6494 s\n",
      "Epoch: 619 Train_loss: 0.820 Val_acc: 0.487 Time consumed: 46.1800 s\n",
      "Epoch: 620 Train_loss: 0.792 Val_acc: 0.544 Time consumed: 46.2394 s\n",
      "Epoch: 621 Train_loss: 0.898 Val_acc: 0.529 Time consumed: 46.2672 s\n",
      "Epoch: 622 Train_loss: 0.917 Val_acc: 0.577 Time consumed: 46.2938 s\n",
      "Epoch: 623 Train_loss: 0.920 Val_acc: 0.420 Time consumed: 46.3025 s\n",
      "Epoch: 624 Train_loss: 0.903 Val_acc: 0.482 Time consumed: 46.0396 s\n",
      "Epoch: 625 Train_loss: 0.884 Val_acc: 0.403 Time consumed: 45.9704 s\n",
      "Epoch: 626 Train_loss: 0.825 Val_acc: 0.395 Time consumed: 46.1329 s\n",
      "Epoch: 627 Train_loss: 0.841 Val_acc: 0.534 Time consumed: 46.2721 s\n",
      "Epoch: 628 Train_loss: 0.906 Val_acc: 0.508 Time consumed: 46.1157 s\n",
      "Epoch: 629 Train_loss: 0.862 Val_acc: 0.404 Time consumed: 45.7108 s\n",
      "Epoch: 630 Train_loss: 0.799 Val_acc: 0.623 Time consumed: 46.3593 s\n",
      "Epoch: 631 Train_loss: 0.902 Val_acc: 0.539 Time consumed: 46.1043 s\n",
      "Epoch: 632 Train_loss: 0.830 Val_acc: 0.514 Time consumed: 46.2266 s\n",
      "Epoch: 633 Train_loss: 0.880 Val_acc: 0.521 Time consumed: 46.2116 s\n",
      "Epoch: 634 Train_loss: 0.895 Val_acc: 0.651 Time consumed: 45.9629 s\n",
      "Epoch: 635 Train_loss: 0.957 Val_acc: 0.315 Time consumed: 46.3176 s\n",
      "Epoch: 636 Train_loss: 0.847 Val_acc: 0.325 Time consumed: 45.6871 s\n",
      "Epoch: 637 Train_loss: 0.891 Val_acc: 0.531 Time consumed: 46.2889 s\n",
      "Epoch: 638 Train_loss: 0.860 Val_acc: 0.512 Time consumed: 46.3947 s\n",
      "Epoch: 639 Train_loss: 0.821 Val_acc: 0.295 Time consumed: 47.2564 s\n",
      "Epoch: 640 Train_loss: 0.886 Val_acc: 0.499 Time consumed: 45.9061 s\n",
      "Epoch: 641 Train_loss: 0.868 Val_acc: 0.656 Time consumed: 46.0913 s\n",
      "Epoch: 642 Train_loss: 0.901 Val_acc: 0.657 Time consumed: 45.8544 s\n",
      "Epoch: 643 Train_loss: 0.846 Val_acc: 0.569 Time consumed: 45.9640 s\n",
      "Epoch: 644 Train_loss: 0.864 Val_acc: 0.365 Time consumed: 46.0094 s\n",
      "Epoch: 645 Train_loss: 0.774 Val_acc: 0.487 Time consumed: 46.0612 s\n",
      "Epoch: 646 Train_loss: 0.864 Val_acc: 0.534 Time consumed: 46.1941 s\n",
      "Epoch: 647 Train_loss: 0.883 Val_acc: 0.368 Time consumed: 45.9842 s\n",
      "Epoch: 648 Train_loss: 0.900 Val_acc: 0.397 Time consumed: 45.8267 s\n",
      "Epoch: 649 Train_loss: 0.887 Val_acc: 0.575 Time consumed: 45.8397 s\n",
      "Epoch: 650 Train_loss: 0.882 Val_acc: 0.359 Time consumed: 46.5022 s\n",
      "Epoch: 651 Train_loss: 0.741 Val_acc: 0.609 Time consumed: 46.1965 s\n",
      "Epoch: 652 Train_loss: 0.861 Val_acc: 0.554 Time consumed: 46.2930 s\n",
      "Epoch: 653 Train_loss: 0.898 Val_acc: 0.644 Time consumed: 46.0645 s\n",
      "Epoch: 654 Train_loss: 0.864 Val_acc: 0.480 Time consumed: 46.4197 s\n",
      "Epoch: 655 Train_loss: 0.932 Val_acc: 0.555 Time consumed: 46.0563 s\n",
      "Epoch: 656 Train_loss: 0.848 Val_acc: 0.628 Time consumed: 46.1190 s\n",
      "Epoch: 657 Train_loss: 0.863 Val_acc: 0.563 Time consumed: 46.3144 s\n",
      "Epoch: 658 Train_loss: 0.916 Val_acc: 0.548 Time consumed: 46.2516 s\n",
      "Epoch: 659 Train_loss: 0.849 Val_acc: 0.550 Time consumed: 46.3660 s\n",
      "Epoch: 660 Train_loss: 0.853 Val_acc: 0.497 Time consumed: 46.0291 s\n",
      "Epoch: 661 Train_loss: 0.893 Val_acc: 0.561 Time consumed: 46.1304 s\n",
      "Epoch: 662 Train_loss: 0.806 Val_acc: 0.368 Time consumed: 46.2461 s\n",
      "Epoch: 663 Train_loss: 0.838 Val_acc: 0.482 Time consumed: 45.7427 s\n",
      "Epoch: 664 Train_loss: 0.828 Val_acc: 0.549 Time consumed: 46.0731 s\n",
      "Epoch: 665 Train_loss: 0.914 Val_acc: 0.560 Time consumed: 45.9488 s\n",
      "Epoch: 666 Train_loss: 0.808 Val_acc: 0.464 Time consumed: 46.0574 s\n",
      "Epoch: 667 Train_loss: 0.914 Val_acc: 0.429 Time consumed: 46.1534 s\n",
      "Epoch: 668 Train_loss: 0.871 Val_acc: 0.523 Time consumed: 46.1005 s\n",
      "Epoch: 669 Train_loss: 0.847 Val_acc: 0.493 Time consumed: 46.1516 s\n",
      "Epoch: 670 Train_loss: 0.875 Val_acc: 0.398 Time consumed: 46.0776 s\n",
      "Epoch: 671 Train_loss: 0.872 Val_acc: 0.523 Time consumed: 46.5544 s\n",
      "Epoch: 672 Train_loss: 0.847 Val_acc: 0.634 Time consumed: 45.8496 s\n",
      "Epoch: 673 Train_loss: 0.875 Val_acc: 0.479 Time consumed: 47.0892 s\n",
      "Epoch: 674 Train_loss: 0.884 Val_acc: 0.432 Time consumed: 45.6170 s\n",
      "Epoch: 675 Train_loss: 0.711 Val_acc: 0.459 Time consumed: 45.9151 s\n",
      "Epoch: 676 Train_loss: 0.883 Val_acc: 0.492 Time consumed: 45.8989 s\n",
      "Epoch: 677 Train_loss: 0.858 Val_acc: 0.508 Time consumed: 46.1615 s\n",
      "Epoch: 678 Train_loss: 0.746 Val_acc: 0.305 Time consumed: 45.6520 s\n",
      "Epoch: 679 Train_loss: 0.819 Val_acc: 0.528 Time consumed: 46.1341 s\n",
      "Epoch: 680 Train_loss: 0.879 Val_acc: 0.480 Time consumed: 45.8930 s\n",
      "Epoch: 681 Train_loss: 0.850 Val_acc: 0.585 Time consumed: 45.8709 s\n",
      "Epoch: 682 Train_loss: 0.908 Val_acc: 0.530 Time consumed: 45.8946 s\n",
      "Epoch: 683 Train_loss: 0.854 Val_acc: 0.511 Time consumed: 45.7923 s\n",
      "Epoch: 684 Train_loss: 0.917 Val_acc: 0.536 Time consumed: 46.0262 s\n",
      "Epoch: 685 Train_loss: 0.883 Val_acc: 0.445 Time consumed: 46.1667 s\n",
      "Epoch: 686 Train_loss: 0.836 Val_acc: 0.612 Time consumed: 45.9697 s\n",
      "Epoch: 687 Train_loss: 0.858 Val_acc: 0.444 Time consumed: 46.2876 s\n",
      "Epoch: 688 Train_loss: 0.848 Val_acc: 0.601 Time consumed: 46.3807 s\n",
      "Epoch: 689 Train_loss: 0.914 Val_acc: 0.551 Time consumed: 46.0798 s\n",
      "Epoch: 690 Train_loss: 0.858 Val_acc: 0.487 Time consumed: 45.9230 s\n",
      "Epoch: 691 Train_loss: 0.859 Val_acc: 0.480 Time consumed: 46.2575 s\n",
      "Epoch: 692 Train_loss: 0.846 Val_acc: 0.472 Time consumed: 45.9878 s\n",
      "Epoch: 693 Train_loss: 0.895 Val_acc: 0.413 Time consumed: 46.1169 s\n",
      "Epoch: 694 Train_loss: 0.872 Val_acc: 0.472 Time consumed: 45.8894 s\n",
      "Epoch: 695 Train_loss: 0.835 Val_acc: 0.612 Time consumed: 46.2249 s\n",
      "Epoch: 696 Train_loss: 0.936 Val_acc: 0.531 Time consumed: 46.0057 s\n",
      "Epoch: 697 Train_loss: 0.836 Val_acc: 0.358 Time consumed: 46.0014 s\n",
      "Epoch: 698 Train_loss: 0.870 Val_acc: 0.486 Time consumed: 45.7744 s\n",
      "Epoch: 699 Train_loss: 0.826 Val_acc: 0.525 Time consumed: 46.3211 s\n",
      "Epoch: 700 Train_loss: 0.880 Val_acc: 0.590 Time consumed: 45.8616 s\n",
      "Epoch: 701 Train_loss: 0.840 Val_acc: 0.456 Time consumed: 46.0017 s\n",
      "Epoch: 702 Train_loss: 0.874 Val_acc: 0.576 Time consumed: 46.2673 s\n",
      "Epoch: 703 Train_loss: 0.871 Val_acc: 0.342 Time consumed: 46.5333 s\n",
      "Epoch: 704 Train_loss: 0.880 Val_acc: 0.512 Time consumed: 46.3025 s\n",
      "Epoch: 705 Train_loss: 0.817 Val_acc: 0.437 Time consumed: 46.0291 s\n",
      "Epoch: 706 Train_loss: 0.829 Val_acc: 0.675 Time consumed: 46.3064 s\n",
      "Epoch: 707 Train_loss: 0.899 Val_acc: 0.270 Time consumed: 47.0304 s\n",
      "Epoch: 708 Train_loss: 0.854 Val_acc: 0.586 Time consumed: 45.6562 s\n",
      "Epoch: 709 Train_loss: 0.812 Val_acc: 0.667 Time consumed: 45.7848 s\n",
      "Epoch: 710 Train_loss: 0.743 Val_acc: 0.526 Time consumed: 45.6780 s\n",
      "Epoch: 711 Train_loss: 0.833 Val_acc: 0.424 Time consumed: 46.1069 s\n",
      "Epoch: 712 Train_loss: 0.821 Val_acc: 0.565 Time consumed: 45.9502 s\n",
      "Epoch: 713 Train_loss: 0.787 Val_acc: 0.489 Time consumed: 46.1535 s\n",
      "Epoch: 714 Train_loss: 0.829 Val_acc: 0.391 Time consumed: 45.8555 s\n",
      "Epoch: 715 Train_loss: 0.795 Val_acc: 0.459 Time consumed: 46.1623 s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 716 Train_loss: 0.860 Val_acc: 0.460 Time consumed: 46.1943 s\n",
      "Epoch: 717 Train_loss: 0.928 Val_acc: 0.466 Time consumed: 46.2055 s\n",
      "Epoch: 718 Train_loss: 0.837 Val_acc: 0.618 Time consumed: 45.9893 s\n",
      "Epoch: 719 Train_loss: 0.883 Val_acc: 0.544 Time consumed: 46.2544 s\n",
      "Epoch: 720 Train_loss: 0.797 Val_acc: 0.512 Time consumed: 46.2129 s\n",
      "Epoch: 721 Train_loss: 0.809 Val_acc: 0.582 Time consumed: 46.3476 s\n",
      "Epoch: 722 Train_loss: 0.756 Val_acc: 0.533 Time consumed: 46.1676 s\n",
      "Epoch: 723 Train_loss: 0.848 Val_acc: 0.458 Time consumed: 46.4650 s\n",
      "Epoch: 724 Train_loss: 0.866 Val_acc: 0.481 Time consumed: 46.0822 s\n",
      "Epoch: 725 Train_loss: 0.910 Val_acc: 0.488 Time consumed: 46.3355 s\n",
      "Epoch: 726 Train_loss: 0.915 Val_acc: 0.649 Time consumed: 46.0896 s\n",
      "Epoch: 727 Train_loss: 0.875 Val_acc: 0.197 Time consumed: 46.2947 s\n",
      "Epoch: 728 Train_loss: 0.919 Val_acc: 0.400 Time consumed: 46.3281 s\n",
      "Epoch: 729 Train_loss: 0.834 Val_acc: 0.359 Time consumed: 46.1694 s\n",
      "Epoch: 730 Train_loss: 0.864 Val_acc: 0.351 Time consumed: 45.7204 s\n",
      "Epoch: 731 Train_loss: 0.899 Val_acc: 0.470 Time consumed: 46.0456 s\n",
      "Epoch: 732 Train_loss: 0.932 Val_acc: 0.427 Time consumed: 46.3384 s\n",
      "Epoch: 733 Train_loss: 0.865 Val_acc: 0.624 Time consumed: 45.8858 s\n",
      "Epoch: 734 Train_loss: 0.922 Val_acc: 0.650 Time consumed: 46.3850 s\n",
      "Epoch: 735 Train_loss: 0.861 Val_acc: 0.429 Time consumed: 46.2535 s\n",
      "Epoch: 736 Train_loss: 0.925 Val_acc: 0.504 Time consumed: 46.3812 s\n",
      "Epoch: 737 Train_loss: 0.781 Val_acc: 0.208 Time consumed: 46.0757 s\n",
      "Epoch: 738 Train_loss: 0.958 Val_acc: 0.522 Time consumed: 46.2601 s\n",
      "Epoch: 739 Train_loss: 0.792 Val_acc: 0.518 Time consumed: 46.2106 s\n",
      "Epoch: 740 Train_loss: 0.760 Val_acc: 0.571 Time consumed: 46.2180 s\n",
      "Epoch: 741 Train_loss: 0.875 Val_acc: 0.376 Time consumed: 47.3616 s\n",
      "Epoch: 742 Train_loss: 0.859 Val_acc: 0.543 Time consumed: 47.0926 s\n",
      "Epoch: 743 Train_loss: 0.907 Val_acc: 0.545 Time consumed: 48.7620 s\n",
      "Epoch: 744 Train_loss: 0.827 Val_acc: 0.591 Time consumed: 47.1185 s\n",
      "Epoch: 745 Train_loss: 0.913 Val_acc: 0.631 Time consumed: 46.0878 s\n",
      "Epoch: 746 Train_loss: 0.849 Val_acc: 0.461 Time consumed: 45.3600 s\n",
      "Epoch: 747 Train_loss: 0.954 Val_acc: 0.584 Time consumed: 45.1874 s\n",
      "Epoch: 748 Train_loss: 0.886 Val_acc: 0.495 Time consumed: 45.6214 s\n",
      "Epoch: 749 Train_loss: 0.825 Val_acc: 0.574 Time consumed: 45.3423 s\n",
      "Epoch: 750 Train_loss: 0.840 Val_acc: 0.526 Time consumed: 45.3588 s\n",
      "Epoch: 751 Train_loss: 0.817 Val_acc: 0.485 Time consumed: 45.5752 s\n",
      "Epoch: 752 Train_loss: 0.891 Val_acc: 0.575 Time consumed: 45.5309 s\n",
      "Epoch: 753 Train_loss: 0.961 Val_acc: 0.447 Time consumed: 45.3155 s\n",
      "Epoch: 754 Train_loss: 0.824 Val_acc: 0.646 Time consumed: 45.7324 s\n",
      "Epoch: 755 Train_loss: 0.873 Val_acc: 0.339 Time consumed: 45.2333 s\n",
      "Epoch: 756 Train_loss: 0.805 Val_acc: 0.569 Time consumed: 45.5172 s\n",
      "Epoch: 757 Train_loss: 0.801 Val_acc: 0.483 Time consumed: 45.6992 s\n",
      "Epoch: 758 Train_loss: 0.829 Val_acc: 0.544 Time consumed: 45.2546 s\n",
      "Epoch: 759 Train_loss: 0.900 Val_acc: 0.569 Time consumed: 45.2292 s\n",
      "Epoch: 760 Train_loss: 0.815 Val_acc: 0.332 Time consumed: 45.2890 s\n",
      "Epoch: 761 Train_loss: 0.818 Val_acc: 0.495 Time consumed: 45.4936 s\n",
      "Epoch: 762 Train_loss: 0.823 Val_acc: 0.599 Time consumed: 45.5390 s\n",
      "Epoch: 763 Train_loss: 0.814 Val_acc: 0.437 Time consumed: 45.4510 s\n",
      "Epoch: 764 Train_loss: 0.814 Val_acc: 0.492 Time consumed: 45.6830 s\n",
      "Epoch: 765 Train_loss: 0.859 Val_acc: 0.587 Time consumed: 45.5101 s\n",
      "Epoch: 766 Train_loss: 0.913 Val_acc: 0.375 Time consumed: 45.5236 s\n",
      "Epoch: 767 Train_loss: 0.845 Val_acc: 0.596 Time consumed: 45.8226 s\n",
      "Epoch: 768 Train_loss: 0.826 Val_acc: 0.552 Time consumed: 48.1291 s\n",
      "Epoch: 769 Train_loss: 0.799 Val_acc: 0.445 Time consumed: 48.8904 s\n",
      "Epoch: 770 Train_loss: 0.810 Val_acc: 0.437 Time consumed: 47.2449 s\n",
      "Epoch: 771 Train_loss: 0.844 Val_acc: 0.596 Time consumed: 46.6200 s\n",
      "Epoch: 772 Train_loss: 0.853 Val_acc: 0.518 Time consumed: 46.9759 s\n",
      "Epoch: 773 Train_loss: 0.831 Val_acc: 0.341 Time consumed: 46.3032 s\n",
      "Epoch: 774 Train_loss: 0.928 Val_acc: 0.599 Time consumed: 46.5816 s\n",
      "Epoch: 775 Train_loss: 0.878 Val_acc: 0.493 Time consumed: 47.2839 s\n",
      "Epoch: 776 Train_loss: 0.827 Val_acc: 0.389 Time consumed: 46.0474 s\n",
      "Epoch: 777 Train_loss: 0.837 Val_acc: 0.511 Time consumed: 46.1667 s\n",
      "Epoch: 778 Train_loss: 0.874 Val_acc: 0.576 Time consumed: 46.0534 s\n",
      "Epoch: 779 Train_loss: 0.876 Val_acc: 0.558 Time consumed: 46.0644 s\n",
      "Epoch: 780 Train_loss: 0.803 Val_acc: 0.560 Time consumed: 46.3672 s\n",
      "Epoch: 781 Train_loss: 0.874 Val_acc: 0.553 Time consumed: 46.2187 s\n",
      "Epoch: 782 Train_loss: 0.841 Val_acc: 0.576 Time consumed: 46.1472 s\n",
      "Epoch: 783 Train_loss: 0.923 Val_acc: 0.454 Time consumed: 45.7435 s\n",
      "Epoch: 784 Train_loss: 0.937 Val_acc: 0.643 Time consumed: 46.3283 s\n",
      "Epoch: 785 Train_loss: 0.861 Val_acc: 0.526 Time consumed: 45.9657 s\n",
      "Epoch: 786 Train_loss: 0.794 Val_acc: 0.534 Time consumed: 46.1010 s\n",
      "Epoch: 787 Train_loss: 0.818 Val_acc: 0.633 Time consumed: 46.0078 s\n",
      "Epoch: 788 Train_loss: 0.823 Val_acc: 0.394 Time consumed: 46.1771 s\n",
      "Epoch: 789 Train_loss: 0.844 Val_acc: 0.503 Time consumed: 46.4113 s\n",
      "Epoch: 790 Train_loss: 0.901 Val_acc: 0.574 Time consumed: 46.1769 s\n",
      "Epoch: 791 Train_loss: 0.837 Val_acc: 0.574 Time consumed: 46.2660 s\n",
      "Epoch: 792 Train_loss: 0.820 Val_acc: 0.537 Time consumed: 46.1614 s\n",
      "Epoch: 793 Train_loss: 0.883 Val_acc: 0.475 Time consumed: 46.0398 s\n",
      "Epoch: 794 Train_loss: 0.888 Val_acc: 0.587 Time consumed: 46.2459 s\n",
      "Epoch: 795 Train_loss: 0.886 Val_acc: 0.457 Time consumed: 46.1232 s\n",
      "Epoch: 796 Train_loss: 0.791 Val_acc: 0.505 Time consumed: 46.3914 s\n",
      "Epoch: 797 Train_loss: 0.839 Val_acc: 0.573 Time consumed: 46.3202 s\n",
      "Epoch: 798 Train_loss: 0.851 Val_acc: 0.511 Time consumed: 46.2124 s\n",
      "Epoch: 799 Train_loss: 0.856 Val_acc: 0.555 Time consumed: 45.9992 s\n",
      "Epoch: 800 Train_loss: 0.923 Val_acc: 0.501 Time consumed: 46.2479 s\n",
      "*****************Training End!*****************\n"
     ]
    }
   ],
   "source": [
    "# gpu_options = tf.GPUOptions(per_process_gpu_memory_fraction=0.9)\n",
    "config = tf.ConfigProto(allow_soft_placement=True,\n",
    "                        log_device_placement=True)\n",
    "config.gpu_options.allow_growth = True\n",
    "\n",
    "with tf.Session(config=config) as sess:\n",
    "\n",
    "    print('*****************Training Start!*****************')\n",
    "    train_writer = tf.summary.FileWriter(path_logdir+'train', sess.graph)\n",
    "#     val_writer = tf.summary.FileWriter(path_logdir+'val', sess.graph)\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "#     saver.restore(sess, path_model+'cifar10.ckpt')\n",
    "\n",
    "    for m in range(epochs):\n",
    "        start = time.time()\n",
    "        batch_gen = datagen.flow(x_train, y_train, batch_size=batch_size*num_gpu)\n",
    "\n",
    "        for i in range(iterations):\n",
    "            x_batch, y_batch = next(batch_gen)\n",
    "            _, loss_train, summary = sess.run([train_op, losses, merged],\n",
    "                                              {inputs: x_batch, outputs: y_batch, is_train: True})\n",
    "            train_writer.add_summary(summary, m * iterations + i)\n",
    "        \n",
    "        val_accs = []\n",
    "        for i in range(5000//(batch_size*num_gpu)):\n",
    "            val_acc = sess.run(accs,{inputs: x_test[i*batch_size*num_gpu:(i+1)*num_gpu*batch_size], \n",
    "                                     outputs: y_test[i*batch_size*num_gpu:(i+1)*num_gpu*batch_size], \n",
    "                                     is_train: False})\n",
    "#             val_writer.add_summary(summary, m)\n",
    "            val_accs.append(val_acc)\n",
    "\n",
    "        if np.mean(val_accs) > old_acc:\n",
    "            old_acc = np.mean(val_accs)\n",
    "            saver.save(sess, path_model+'cifar10.ckpt')\n",
    "\n",
    "#         if loss_train == 0:\n",
    "#             break\n",
    "\n",
    "        end = time.time()\n",
    "        print('Epoch: {}'.format(m + 1),\n",
    "              'Train_loss: {:.3f}'.format(loss_train),\n",
    "              'Val_acc: {:.3f}'.format(np.mean(val_accs)),\n",
    "              'Time consumed: {:.4f} s'.format(end - start))\n",
    "\n",
    "    print('*****************Training End!*****************')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
